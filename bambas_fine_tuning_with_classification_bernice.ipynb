{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DW3OQVqUYC0z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0013fb9-439b-424d-8cdd-b16613affeff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mabsl-py==1.4.0\n",
            "accelerate==0.21.0\n",
            "aiohttp==3.9.3\n",
            "aiosignal==1.3.1\n",
            "alabaster==0.7.16\n",
            "albumentations==1.3.1\n",
            "alembic==1.13.1\n",
            "altair==4.2.2\n",
            "annotated-types==0.6.0\n",
            "anyio==3.7.1\n",
            "appdirs==1.4.4\n",
            "argon2-cffi==23.1.0\n",
            "argon2-cffi-bindings==21.2.0\n",
            "array-record==0.5.0\n",
            "arviz==0.15.1\n",
            "astropy==5.3.4\n",
            "astunparse==1.6.3\n",
            "async-timeout==4.0.3\n",
            "atpublic==4.0\n",
            "attrs==23.2.0\n",
            "audioread==3.0.1\n",
            "autograd==1.6.2\n",
            "Babel==2.14.0\n",
            "backcall==0.2.0\n",
            "beautifulsoup4==4.12.3\n",
            "bidict==0.22.1\n",
            "bigframes==0.20.1\n",
            "bitsandbytes==0.40.2\n",
            "bleach==6.1.0\n",
            "blinker==1.4\n",
            "blis==0.7.11\n",
            "blosc2==2.0.0\n",
            "bokeh==3.3.4\n",
            "bqplot==0.12.42\n",
            "branca==0.7.1\n",
            "build==1.0.3\n",
            "CacheControl==0.14.0\n",
            "cachetools==5.3.2\n",
            "catalogue==2.0.10\n",
            "certifi==2024.2.2\n",
            "cffi==1.16.0\n",
            "chardet==5.2.0\n",
            "charset-normalizer==3.3.2\n",
            "chex==0.1.85\n",
            "click==8.1.7\n",
            "click-plugins==1.1.1\n",
            "cligj==0.7.2\n",
            "cloudpathlib==0.16.0\n",
            "cloudpickle==2.2.1\n",
            "cmake==3.27.9\n",
            "cmdstanpy==1.2.1\n",
            "colorcet==3.0.1\n",
            "colorlog==6.8.2\n",
            "colorlover==0.3.0\n",
            "colour==0.1.5\n",
            "community==1.0.0b1\n",
            "confection==0.1.4\n",
            "cons==0.4.6\n",
            "contextlib2==21.6.0\n",
            "contourpy==1.2.0\n",
            "cryptography==42.0.2\n",
            "cufflinks==0.17.3\n",
            "cupy-cuda12x==12.2.0\n",
            "cvxopt==1.3.2\n",
            "cvxpy==1.3.3\n",
            "cycler==0.12.1\n",
            "cymem==2.0.8\n",
            "Cython==3.0.8\n",
            "dask==2023.8.1\n",
            "datascience==0.17.6\n",
            "datasets==2.4.0\n",
            "db-dtypes==1.2.0\n",
            "dbus-python==1.2.18\n",
            "debugpy==1.6.6\n",
            "decorator==4.4.2\n",
            "defusedxml==0.7.1\n",
            "dill==0.3.5.1\n",
            "diskcache==5.6.3\n",
            "distributed==2023.8.1\n",
            "distro==1.7.0\n",
            "dlib==19.24.2\n",
            "dm-tree==0.1.8\n",
            "docker-pycreds==0.4.0\n",
            "docutils==0.18.1\n",
            "dopamine-rl==4.0.6\n",
            "duckdb==0.9.2\n",
            "earthengine-api==0.1.389\n",
            "easydict==1.12\n",
            "ecos==2.0.13\n",
            "editdistance==0.6.2\n",
            "eerepr==0.0.4\n",
            "en-core-web-sm @ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl#sha256=86cc141f63942d4b2c5fcee06630fd6f904788d2f0ab005cce45aadb8fb73889\n",
            "entrypoints==0.4\n",
            "et-xmlfile==1.1.0\n",
            "etils==1.6.0\n",
            "etuples==0.3.9\n",
            "exceptiongroup==1.2.0\n",
            "fastai==2.7.14\n",
            "fastcore==1.5.29\n",
            "fastdownload==0.0.7\n",
            "fastjsonschema==2.19.1\n",
            "fastprogress==1.0.3\n",
            "fastrlock==0.8.2\n",
            "filelock==3.13.1\n",
            "fiona==1.9.5\n",
            "firebase-admin==5.3.0\n",
            "Flask==2.2.5\n",
            "flatbuffers==23.5.26\n",
            "flax==0.8.1\n",
            "folium==0.14.0\n",
            "fonttools==4.48.1\n",
            "frozendict==2.4.0\n",
            "frozenlist==1.4.1\n",
            "fsspec==2023.6.0\n",
            "future==0.18.3\n",
            "gast==0.5.4\n",
            "gcsfs==2023.6.0\n",
            "GDAL==3.6.4\n",
            "gdown==4.7.3\n",
            "geemap==0.30.4\n",
            "gensim==4.3.2\n",
            "geocoder==1.38.1\n",
            "geographiclib==2.0\n",
            "geopandas==0.13.2\n",
            "geopy==2.3.0\n",
            "gin-config==0.5.0\n",
            "gitdb==4.0.11\n",
            "GitPython==3.1.42\n",
            "glob2==0.7\n",
            "google==2.0.3\n",
            "google-ai-generativelanguage==0.4.0\n",
            "google-api-core==2.11.1\n",
            "google-api-python-client==2.84.0\n",
            "google-auth==2.27.0\n",
            "google-auth-httplib2==0.1.1\n",
            "google-auth-oauthlib==1.2.0\n",
            "google-cloud-aiplatform==1.39.0\n",
            "google-cloud-bigquery==3.12.0\n",
            "google-cloud-bigquery-connection==1.12.1\n",
            "google-cloud-bigquery-storage==2.24.0\n",
            "google-cloud-core==2.3.3\n",
            "google-cloud-datastore==2.15.2\n",
            "google-cloud-firestore==2.11.1\n",
            "google-cloud-functions==1.13.3\n",
            "google-cloud-iam==2.14.1\n",
            "google-cloud-language==2.9.1\n",
            "google-cloud-resource-manager==1.12.1\n",
            "google-cloud-storage==2.8.0\n",
            "google-cloud-translate==3.11.3\n",
            "google-colab @ file:///colabtools/dist/google-colab-1.0.0.tar.gz#sha256=7b49a8ec5e4d2c9b20d2bf9f5ef7129b9a3d02b2c6e5497e989d74c744ab9fe6\n",
            "google-crc32c==1.5.0\n",
            "google-generativeai==0.3.2\n",
            "google-pasta==0.2.0\n",
            "google-resumable-media==2.7.0\n",
            "googleapis-common-protos==1.62.0\n",
            "googledrivedownloader==0.4\n",
            "graphviz==0.20.1\n",
            "greenlet==3.0.3\n",
            "grpc-google-iam-v1==0.13.0\n",
            "grpcio==1.60.1\n",
            "grpcio-status==1.48.2\n",
            "gspread==3.4.2\n",
            "gspread-dataframe==3.3.1\n",
            "gym==0.25.2\n",
            "gym-notices==0.0.8\n",
            "h5netcdf==1.3.0\n",
            "h5py==3.9.0\n",
            "holidays==0.42\n",
            "holoviews==1.17.1\n",
            "html5lib==1.1\n",
            "httpimport==1.3.1\n",
            "httplib2==0.22.0\n",
            "huggingface-hub==0.20.3\n",
            "humanize==4.7.0\n",
            "hyperopt==0.2.7\n",
            "ibis-framework==7.1.0\n",
            "idna==3.6\n",
            "imageio==2.31.6\n",
            "imageio-ffmpeg==0.4.9\n",
            "imagesize==1.4.1\n",
            "imbalanced-learn==0.10.1\n",
            "imgaug==0.4.0\n",
            "importlib-metadata==7.0.1\n",
            "importlib-resources==6.1.1\n",
            "imutils==0.5.4\n",
            "inflect==7.0.0\n",
            "iniconfig==2.0.0\n",
            "install==1.3.5\n",
            "intel-openmp==2023.2.3\n",
            "ipyevents==2.0.2\n",
            "ipyfilechooser==0.6.0\n",
            "ipykernel==5.5.6\n",
            "ipyleaflet==0.18.2\n",
            "ipython==7.34.0\n",
            "ipython-genutils==0.2.0\n",
            "ipython-sql==0.5.0\n",
            "ipytree==0.2.2\n",
            "ipywidgets==7.7.1\n",
            "itsdangerous==2.1.2\n",
            "jax==0.4.23\n",
            "jaxlib @ https://storage.googleapis.com/jax-releases/cuda12/jaxlib-0.4.23+cuda12.cudnn89-cp310-cp310-manylinux2014_x86_64.whl#sha256=8e42000672599e7ec0ea7f551acfcc95dcdd0e22b05a1d1f12f97b56a9fce4a8\n",
            "jeepney==0.7.1\n",
            "jieba==0.42.1\n",
            "Jinja2==3.1.3\n",
            "joblib==1.3.2\n",
            "jsonpickle==3.0.2\n",
            "jsonschema==4.19.2\n",
            "jsonschema-specifications==2023.12.1\n",
            "jupyter-client==6.1.12\n",
            "jupyter-console==6.1.0\n",
            "jupyter-server==1.24.0\n",
            "jupyter_core==5.7.1\n",
            "jupyterlab_pygments==0.3.0\n",
            "jupyterlab_widgets==3.0.10\n",
            "kaggle==1.5.16\n",
            "kagglehub==0.1.9\n",
            "keras==2.15.0\n",
            "keyring==23.5.0\n",
            "kiwisolver==1.4.5\n",
            "langcodes==3.3.0\n",
            "launchpadlib==1.10.16\n",
            "lazr.restfulclient==0.14.4\n",
            "lazr.uri==1.0.6\n",
            "lazy_loader==0.3\n",
            "libclang==16.0.6\n",
            "librosa==0.10.1\n",
            "lida==0.0.10\n",
            "lightgbm==4.1.0\n",
            "linkify-it-py==2.0.3\n",
            "llmx==0.0.15a0\n",
            "llvmlite==0.41.1\n",
            "locket==1.0.0\n",
            "logical-unification==0.4.6\n",
            "lxml==4.9.4\n",
            "Mako==1.3.2\n",
            "malloy==2023.1067\n",
            "Markdown==3.5.2\n",
            "markdown-it-py==3.0.0\n",
            "MarkupSafe==2.1.5\n",
            "matplotlib==3.7.1\n",
            "matplotlib-inline==0.1.6\n",
            "matplotlib-venn==0.11.10\n",
            "mdit-py-plugins==0.4.0\n",
            "mdurl==0.1.2\n",
            "miniKanren==1.0.3\n",
            "missingno==0.5.2\n",
            "mistune==0.8.4\n",
            "mizani==0.9.3\n",
            "mkl==2023.2.0\n",
            "ml-dtypes==0.2.0\n",
            "mlxtend==0.22.0\n",
            "more-itertools==10.1.0\n",
            "moviepy==1.0.3\n",
            "mpmath==1.3.0\n",
            "msgpack==1.0.7\n",
            "multidict==6.0.5\n",
            "multipledispatch==1.0.0\n",
            "multiprocess==0.70.13\n",
            "multitasking==0.0.11\n",
            "murmurhash==1.0.10\n",
            "music21==9.1.0\n",
            "natsort==8.4.0\n",
            "nbclassic==1.0.0\n",
            "nbclient==0.9.0\n",
            "nbconvert==6.5.4\n",
            "nbformat==5.9.2\n",
            "nest-asyncio==1.6.0\n",
            "networkx==3.2.1\n",
            "nibabel==4.0.2\n",
            "nltk==3.8.1\n",
            "notebook==6.5.5\n",
            "notebook_shim==0.2.3\n",
            "numba==0.58.1\n",
            "numexpr==2.9.0\n",
            "numpy==1.25.2\n",
            "oauth2client==4.1.3\n",
            "oauthlib==3.2.2\n",
            "openai==0.22.0\n",
            "opencv-contrib-python==4.8.0.76\n",
            "opencv-python==4.8.0.76\n",
            "opencv-python-headless==4.9.0.80\n",
            "openpyxl==3.1.2\n",
            "opt-einsum==3.3.0\n",
            "optax==0.1.9\n",
            "optuna==3.5.0\n",
            "orbax-checkpoint==0.4.4\n",
            "osqp==0.6.2.post8\n",
            "packaging==23.2\n",
            "pandas==1.5.3\n",
            "pandas-datareader==0.10.0\n",
            "pandas-gbq==0.19.2\n",
            "pandas-stubs==1.5.3.230304\n",
            "pandocfilters==1.5.1\n",
            "panel==1.3.8\n",
            "param==2.0.2\n",
            "parso==0.8.3\n",
            "parsy==2.1\n",
            "partd==1.4.1\n",
            "pathlib==1.0.1\n",
            "pathtools==0.1.2\n",
            "patsy==0.5.6\n",
            "peewee==3.17.1\n",
            "peft==0.4.0\n",
            "pexpect==4.9.0\n",
            "pickleshare==0.7.5\n",
            "Pillow==9.4.0\n",
            "pins==0.8.4\n",
            "pip-tools==6.13.0\n",
            "platformdirs==4.2.0\n",
            "plotly==5.15.0\n",
            "plotnine==0.12.4\n",
            "pluggy==1.4.0\n",
            "polars==0.20.2\n",
            "pooch==1.8.0\n",
            "portpicker==1.5.2\n",
            "prefetch-generator==1.0.3\n",
            "preshed==3.0.9\n",
            "prettytable==3.9.0\n",
            "proglog==0.1.10\n",
            "progressbar2==4.2.0\n",
            "prometheus-client==0.19.0\n",
            "promise==2.3\n",
            "prompt-toolkit==3.0.43\n",
            "prophet==1.1.5\n",
            "proto-plus==1.23.0\n",
            "protobuf==3.20.3\n",
            "psutil==5.9.5\n",
            "psycopg2==2.9.9\n",
            "ptyprocess==0.7.0\n",
            "py-cpuinfo==9.0.0\n",
            "py4j==0.10.9.7\n",
            "pyarrow==10.0.1\n",
            "pyarrow-hotfix==0.6\n",
            "pyasn1==0.5.1\n",
            "pyasn1-modules==0.3.0\n",
            "pycocotools==2.0.7\n",
            "pycparser==2.21\n",
            "pyct==0.5.0\n",
            "pydantic==2.6.1\n",
            "pydantic_core==2.16.2\n",
            "pydata-google-auth==1.8.2\n",
            "pydot==1.4.2\n",
            "pydot-ng==2.0.0\n",
            "pydotplus==2.0.2\n",
            "PyDrive==1.3.1\n",
            "PyDrive2==1.6.3\n",
            "pyerfa==2.0.1.1\n",
            "pygame==2.5.2\n",
            "Pygments==2.16.1\n",
            "PyGObject==3.42.1\n",
            "PyJWT==2.3.0\n",
            "pymc==5.7.2\n",
            "pymystem3==0.2.0\n",
            "PyOpenGL==3.1.7\n",
            "pyOpenSSL==24.0.0\n",
            "pyparsing==3.1.1\n",
            "pyperclip==1.8.2\n",
            "pyproj==3.6.1\n",
            "pyproject_hooks==1.0.0\n",
            "pyshp==2.3.1\n",
            "PySocks==1.7.1\n",
            "pytensor==2.14.2\n",
            "pytest==7.4.4\n",
            "python-apt @ file:///backend-container/containers/python_apt-0.0.0-cp310-cp310-linux_x86_64.whl#sha256=b209c7165d6061963abe611492f8c91c3bcef4b7a6600f966bab58900c63fefa\n",
            "python-box==7.1.1\n",
            "python-dateutil==2.8.2\n",
            "python-louvain==0.16\n",
            "python-slugify==8.0.4\n",
            "python-utils==3.8.2\n",
            "pytz==2023.4\n",
            "pyviz_comms==3.0.1\n",
            "PyWavelets==1.5.0\n",
            "PyYAML==6.0.1\n",
            "pyzmq==23.2.1\n",
            "qdldl==0.1.7.post0\n",
            "qudida==0.0.4\n",
            "ratelim==0.1.6\n",
            "referencing==0.33.0\n",
            "regex==2023.12.25\n",
            "requests==2.31.0\n",
            "requests-oauthlib==1.3.1\n",
            "requirements-parser==0.5.0\n",
            "responses==0.18.0\n",
            "rich==13.7.0\n",
            "rpds-py==0.17.1\n",
            "rpy2==3.4.2\n",
            "rsa==4.9\n",
            "safetensors==0.4.2\n",
            "scikit-image==0.19.3\n",
            "scikit-learn==1.2.2\n",
            "scikit-multilearn==0.2.0\n",
            "scipy==1.11.4\n",
            "scooby==0.9.2\n",
            "scs==3.2.4.post1\n",
            "seaborn==0.13.1\n",
            "SecretStorage==3.3.1\n",
            "Send2Trash==1.8.2\n",
            "sentence-transformers==2.2.2\n",
            "sentencepiece==0.1.99\n",
            "sentry-sdk==1.40.4\n",
            "setproctitle==1.3.3\n",
            "shapely==2.0.2\n",
            "shortuuid==1.0.11\n",
            "six==1.16.0\n",
            "sklearn-pandas==2.2.0\n",
            "smart-open==6.4.0\n",
            "smmap==5.0.1\n",
            "sniffio==1.3.0\n",
            "snowballstemmer==2.2.0\n",
            "sortedcontainers==2.4.0\n",
            "soundfile==0.12.1\n",
            "soupsieve==2.5\n",
            "soxr==0.3.7\n",
            "spacy==3.7.2\n",
            "spacy-legacy==3.0.12\n",
            "spacy-loggers==1.0.5\n",
            "Sphinx==5.0.2\n",
            "sphinxcontrib-applehelp==1.0.8\n",
            "sphinxcontrib-devhelp==1.0.6\n",
            "sphinxcontrib-htmlhelp==2.0.5\n",
            "sphinxcontrib-jsmath==1.0.1\n",
            "sphinxcontrib-qthelp==1.0.7\n",
            "sphinxcontrib-serializinghtml==1.1.10\n",
            "SQLAlchemy==2.0.27\n",
            "sqlglot==19.9.0\n",
            "sqlparse==0.4.4\n",
            "srsly==2.4.8\n",
            "stanio==0.3.0\n",
            "statsmodels==0.14.1\n",
            "sympy==1.12\n",
            "tables==3.8.0\n",
            "tabulate==0.9.0\n",
            "tbb==2021.11.0\n",
            "tblib==3.0.0\n",
            "tenacity==8.2.3\n",
            "tensorboard==2.15.2\n",
            "tensorboard-data-server==0.7.2\n",
            "tensorflow==2.15.0\n",
            "tensorflow-datasets==4.9.4\n",
            "tensorflow-estimator==2.15.0\n",
            "tensorflow-gcs-config==2.15.0\n",
            "tensorflow-hub==0.16.1\n",
            "tensorflow-io-gcs-filesystem==0.36.0\n",
            "tensorflow-metadata==1.14.0\n",
            "tensorflow-probability==0.23.0\n",
            "tensorstore==0.1.45\n",
            "termcolor==2.4.0\n",
            "terminado==0.18.0\n",
            "text-unidecode==1.3\n",
            "textblob==0.17.1\n",
            "tf-keras==2.15.0\n",
            "tf-slim==1.1.0\n",
            "thinc==8.2.3\n",
            "threadpoolctl==3.2.0\n",
            "tifffile==2024.2.12\n",
            "tinycss2==1.2.1\n",
            "tokenizers==0.13.3\n",
            "toml==0.10.2\n",
            "tomli==2.0.1\n",
            "toolz==0.12.1\n",
            "torch @ https://download.pytorch.org/whl/cu121/torch-2.1.0%2Bcu121-cp310-cp310-linux_x86_64.whl#sha256=0d4e8c52a1fcf5ed6cfc256d9a370fcf4360958fc79d0b08a51d55e70914df46\n",
            "torchaudio @ https://download.pytorch.org/whl/cu121/torchaudio-2.1.0%2Bcu121-cp310-cp310-linux_x86_64.whl#sha256=676bda4042734eda99bc59b2d7f761f345d3cde0cad492ad34e3aefde688c6d8\n",
            "torchdata==0.7.0\n",
            "torchsummary==1.5.1\n",
            "torchtext==0.16.0\n",
            "torchvision @ https://download.pytorch.org/whl/cu121/torchvision-0.16.0%2Bcu121-cp310-cp310-linux_x86_64.whl#sha256=e76e78d0ad43636c9884b3084ffaea8a8b61f21129fbfa456a5fe734f0affea9\n",
            "tornado==6.3.2\n",
            "tqdm==4.66.2\n",
            "traitlets==5.7.1\n",
            "traittypes==0.2.1\n",
            "transformers==4.31.0\n",
            "triton==2.1.0\n",
            "trl==0.4.7\n",
            "tweepy==4.14.0\n",
            "typer==0.9.0\n",
            "types-pytz==2024.1.0.20240203\n",
            "types-setuptools==69.0.0.20240125\n",
            "typing_extensions==4.9.0\n",
            "tzlocal==5.2\n",
            "uc-micro-py==1.0.3\n",
            "uritemplate==4.1.1\n",
            "urllib3==2.0.7\n",
            "vega-datasets==0.9.0\n",
            "wadllib==1.3.6\n",
            "wandb==0.12.19\n",
            "wasabi==1.1.2\n",
            "wcwidth==0.2.13\n",
            "weasel==0.3.4\n",
            "webcolors==1.13\n",
            "webencodings==0.5.1\n",
            "websocket-client==1.7.0\n",
            "Werkzeug==3.0.1\n",
            "widgetsnbextension==3.6.6\n",
            "wordcloud==1.9.3\n",
            "wrapt==1.14.1\n",
            "xarray==2023.7.0\n",
            "xarray-einstats==0.7.0\n",
            "xgboost==2.0.3\n",
            "xlrd==2.0.1\n",
            "xxhash==3.4.1\n",
            "xyzservices==2023.10.1\n",
            "yarl==1.9.4\n",
            "yellowbrick==1.5\n",
            "yfinance==0.2.36\n",
            "zict==3.0.0\n",
            "zipp==3.17.0\n"
          ]
        }
      ],
      "source": [
        "!pip install -q accelerate==0.21.0 peft==0.4.0 bitsandbytes==0.40.2 transformers==4.31.0 trl==0.4.7 datasets==2.4.0 huggingface_hub matplotlib numpy>=1.25 openai==0.22.0 wandb==0.12.19 pandas requests scikit_learn scipy gensim sentence-transformers scikit-multilearn imbalanced-learn optuna\n",
        "#!pip install sklearn-hierarchical-classification\n",
        "# !pip install -q accelerate peft bitsandbytes transformers trl datasets huggingface_hub matplotlib numpy openai wandb pandas requests scikit_learn scipy gensim\n",
        "!pip freeze > requirements.txt\n",
        "!cat requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GLGv8lVuYC00",
        "outputId": "23f77f91-93f6-4b9f-e2b6-c50bdec0a09e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/gdrive\")\n",
        "import os\n",
        "os.environ[\"COLAB_WORKDIR\"] = \"/gdrive/My Drive/projects/bambas\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!echo $COLAB_WORKDIR\n",
        "!git clone https://github.com/lfmatosm/sklearn-hierarchical-classification.git\n",
        "!pip install ./sklearn-hierarchical-classification"
      ],
      "metadata": {
        "id": "Seupsx5902yc",
        "outputId": "22c6bf4c-bfdb-4489-f469-4199600af5be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/gdrive/My Drive/projects/bambas\n",
            "Cloning into 'sklearn-hierarchical-classification'...\n",
            "remote: Enumerating objects: 760, done.\u001b[K\n",
            "remote: Counting objects: 100% (139/139), done.\u001b[K\n",
            "remote: Compressing objects: 100% (20/20), done.\u001b[K\n",
            "remote: Total 760 (delta 127), reused 121 (delta 119), pack-reused 621\u001b[K\n",
            "Receiving objects: 100% (760/760), 139.46 KiB | 12.68 MiB/s, done.\n",
            "Resolving deltas: 100% (500/500), done.\n",
            "Processing ./sklearn-hierarchical-classification\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: networkx>=2.4 in /usr/local/lib/python3.10/dist-packages (from sklearn-hierarchical-classification==1.3.2) (3.2.1)\n",
            "Requirement already satisfied: numpy>=1.13.1 in /usr/local/lib/python3.10/dist-packages (from sklearn-hierarchical-classification==1.3.2) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from sklearn-hierarchical-classification==1.3.2) (1.2.2)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from sklearn-hierarchical-classification==1.3.2) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.19.0->sklearn-hierarchical-classification==1.3.2) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.19.0->sklearn-hierarchical-classification==1.3.2) (3.2.0)\n",
            "Building wheels for collected packages: sklearn-hierarchical-classification\n",
            "  Building wheel for sklearn-hierarchical-classification (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sklearn-hierarchical-classification: filename=sklearn_hierarchical_classification-1.3.2-py3-none-any.whl size=23601 sha256=a0f41bc6b4fea4fcc5ef6a2470644384b7c9c8c161acfba6a2e46c6fedfd39c2\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/f7/f6/5636c8150b98522ffa516cf2ebf0a699b64576b9abd58ae843\n",
            "Successfully built sklearn-hierarchical-classification\n",
            "Installing collected packages: sklearn-hierarchical-classification\n",
            "Successfully installed sklearn-hierarchical-classification-1.3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fine-tuning + classification head with Semeval2024 and BERNICE model"
      ],
      "metadata": {
        "id": "evd93FHHzRyH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!PYTHONPATH=\"/gdrive/My Drive/projects/bambas\" python -m src.fine_tuning_with_class \\\n",
        "  --model jhu-clsp/bernice \\\n",
        "  --dataset semeval2024_dev_labeled \\\n",
        "  --fine_tuned_name jhu-clsp-bernice-semeval2024-dev-labeled-classifier \\\n",
        "  --batch_size 8 \\\n",
        "  --save_strategy epoch \\\n",
        "  --lr 3.9e-5 \\\n",
        "  --epochs 5 \\\n",
        "  --save_model"
      ],
      "metadata": {
        "id": "HumO1hktKJO3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d3e1360-15e8-478f-bab0-0bd4165ea21c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-02-14 23:31:02.614454: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-02-14 23:31:02.614500: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-02-14 23:31:02.615988: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-02-14 23:31:03.762941: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Running on Google Colab, workdir: /gdrive/My Drive/projects/bambas\n",
            "Running on Google Colab, workdir: /gdrive/My Drive/projects/bambas\n",
            "Running on Google Colab, workdir: /gdrive/My Drive/projects/bambas\n",
            "Running on Google Colab, workdir: /gdrive/My Drive/projects/bambas\n",
            "Running on Google Colab, workdir: /gdrive/My Drive/projects/bambas\n",
            "Running on Google Colab, workdir: /gdrive/My Drive/projects/bambas\n",
            "Arguments: Namespace(model='jhu-clsp/bernice', dataset='semeval2024_dev_labeled', fine_tuned_name='jhu-clsp-bernice-semeval2024-dev-labeled-classifier', batch_size=8, max_length=128, lr=3.9e-05, weight_decay=0.001, save_model=True, concat_train_dev=False, hypsearch=False, hpsearch_min=3.9e-05, hpsearch_max=3.9e-05, n_trials=10, epochs=5, push_model_to_hf_hub=False, save_strategy='epoch')\n",
            "Using device: {'': 0}\n",
            "#0:  11% 23/219 [00:00<00:01, 108.61ba/s]\n",
            "#0:  16% 34/219 [00:00<00:01, 101.96ba/s]\n",
            "#0:  21% 46/219 [00:00<00:01, 106.65ba/s]\n",
            "#0:  27% 59/219 [00:00<00:01, 112.66ba/s]\n",
            "#0:  33% 73/219 [00:00<00:01, 119.10ba/s]\n",
            "#0:  40% 87/219 [00:00<00:01, 124.33ba/s]\n",
            "#0:  46% 100/219 [00:00<00:00, 123.28ba/s]\n",
            "\n",
            "#2:   0% 0/219 [00:00<?, ?ba/s]\u001b[A\u001b[A\n",
            "#0:  52% 114/219 [00:00<00:00, 127.43ba/s]\n",
            "\n",
            "#2:   3% 7/219 [00:00<00:03, 63.46ba/s]\u001b[A\u001b[A\n",
            "#0:  61% 133/219 [00:01<00:00, 145.88ba/s]\n",
            "\n",
            "#2:   9% 20/219 [00:00<00:02, 93.47ba/s]\u001b[A\u001b[A\n",
            "#1:  43% 94/219 [00:00<00:01, 115.37ba/s]\u001b[A\n",
            "\n",
            "\n",
            "#0:  68% 148/219 [00:01<00:00, 144.13ba/s]\n",
            "\n",
            "#2:  15% 33/219 [00:00<00:01, 108.65ba/s]\u001b[A\u001b[A\n",
            "#1:  49% 107/219 [00:00<00:00, 118.94ba/s]\u001b[A\n",
            "\n",
            "\n",
            "#0:  74% 163/219 [00:01<00:00, 134.63ba/s]\n",
            "\n",
            "#2:  22% 48/219 [00:00<00:01, 122.55ba/s]\u001b[A\u001b[A\n",
            "#1:  54% 119/219 [00:01<00:00, 115.45ba/s]\u001b[A\n",
            "\n",
            "\n",
            "#3:   9% 19/219 [00:00<00:02, 94.81ba/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "#0:  81% 177/219 [00:01<00:00, 130.94ba/s]\n",
            "#1:  60% 131/219 [00:01<00:00, 114.16ba/s]\u001b[A\n",
            "\n",
            "\n",
            "#0:  87% 191/219 [00:01<00:00, 130.26ba/s]\n",
            "#1:  69% 151/219 [00:01<00:00, 138.51ba/s]\u001b[A\n",
            "\n",
            "#2:  39% 85/219 [00:00<00:00, 140.22ba/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "#0:  94% 206/219 [00:01<00:00, 133.08ba/s]\n",
            "\n",
            "#2:  46% 100/219 [00:00<00:00, 139.04ba/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "#3:  26% 58/219 [00:00<00:01, 117.60ba/s]\u001b[A\u001b[A\u001b[A\n",
            "#0: 100% 219/219 [00:01<00:00, 126.69ba/s]\n",
            "\n",
            "\n",
            "\n",
            "#3:  32% 71/219 [00:00<00:01, 120.97ba/s]\u001b[A\u001b[A\u001b[A\n",
            "#1:  82% 180/219 [00:01<00:00, 132.80ba/s]\u001b[A\n",
            "\n",
            "#2:  53% 115/219 [00:00<00:00, 134.39ba/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "#3:  39% 85/219 [00:00<00:01, 125.29ba/s]\u001b[A\u001b[A\u001b[A\n",
            "#1:  89% 195/219 [00:01<00:00, 136.17ba/s]\u001b[A\n",
            "\n",
            "#2:  59% 130/219 [00:01<00:00, 134.65ba/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "#3:  45% 98/219 [00:00<00:00, 122.31ba/s]\u001b[A\u001b[A\u001b[A\n",
            "#1:  95% 209/219 [00:01<00:00, 121.31ba/s]\u001b[A\n",
            "\n",
            "#2:  66% 144/219 [00:01<00:00, 125.12ba/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "#1: 100% 219/219 [00:01<00:00, 119.50ba/s]\n",
            "\n",
            "\n",
            "#2:  72% 158/219 [00:01<00:00, 128.55ba/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "#3:  60% 131/219 [00:01<00:00, 137.02ba/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "#2:  79% 172/219 [00:01<00:00, 123.69ba/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "#3:  67% 146/219 [00:01<00:00, 138.66ba/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "#2:  85% 186/219 [00:01<00:00, 125.35ba/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "#3:  73% 160/219 [00:01<00:00, 131.24ba/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "#2:  91% 199/219 [00:01<00:00, 122.73ba/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "#3:  79% 174/219 [00:01<00:00, 133.07ba/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "#2: 100% 219/219 [00:01<00:00, 127.58ba/s]\n",
            "\n",
            "\n",
            "\n",
            "#3:  86% 189/219 [00:01<00:00, 135.39ba/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "#3: 100% 219/219 [00:01<00:00, 135.58ba/s]\n",
            "#0: 100% 16/16 [00:00<00:00, 102.36ba/s]\n",
            "\n",
            "#1:   0% 0/16 [00:00<?, ?ba/s]\u001b[A\n",
            "#1:  19% 3/16 [00:00<00:00, 27.08ba/s]\u001b[A\n",
            "#1: 100% 16/16 [00:00<00:00, 58.50ba/s]\n",
            "\n",
            "\n",
            "#2:   0% 0/16 [00:00<?, ?ba/s]\u001b[A\u001b[A\n",
            "\n",
            "#2:  56% 9/16 [00:00<00:00, 84.51ba/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "#2: 100% 16/16 [00:00<00:00, 98.26ba/s]\n",
            "\n",
            "\n",
            "\n",
            "#3: 100% 16/16 [00:00<00:00, 98.21ba/s]\n",
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at jhu-clsp/bernice and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "  0% 0/4375 [00:00<?, ?it/s]You're using a XLMRobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "{'loss': 0.1815, 'learning_rate': 3.454285714285714e-05, 'epoch': 0.57}\n",
            " 20% 875/4375 [03:43<14:32,  4.01it/s]\n",
            "  0% 0/63 [00:00<?, ?it/s]\u001b[A\n",
            "  6% 4/63 [00:00<00:01, 34.23it/s]\u001b[A\n",
            " 13% 8/63 [00:00<00:02, 26.28it/s]\u001b[A\n",
            " 17% 11/63 [00:00<00:02, 24.35it/s]\u001b[A\n",
            " 24% 15/63 [00:00<00:01, 27.90it/s]\u001b[A\n",
            " 29% 18/63 [00:00<00:01, 26.23it/s]\u001b[A\n",
            " 33% 21/63 [00:00<00:01, 25.08it/s]\u001b[A\n",
            " 38% 24/63 [00:00<00:01, 23.39it/s]\u001b[A\n",
            " 43% 27/63 [00:01<00:01, 22.89it/s]\u001b[A\n",
            " 49% 31/63 [00:01<00:01, 26.67it/s]\u001b[A\n",
            " 54% 34/63 [00:01<00:01, 26.31it/s]\u001b[A\n",
            " 59% 37/63 [00:01<00:01, 23.90it/s]\u001b[A\n",
            " 63% 40/63 [00:01<00:00, 24.56it/s]\u001b[A\n",
            " 70% 44/63 [00:01<00:00, 25.34it/s]\u001b[A\n",
            " 75% 47/63 [00:01<00:00, 23.20it/s]\u001b[A\n",
            " 79% 50/63 [00:02<00:00, 22.08it/s]\u001b[A\n",
            " 84% 53/63 [00:02<00:00, 20.66it/s]\u001b[A\n",
            " 89% 56/63 [00:02<00:00, 20.01it/s]\u001b[A\n",
            " 94% 59/63 [00:02<00:00, 19.33it/s]\u001b[A\n",
            " 97% 61/63 [00:02<00:00, 19.05it/s]\u001b[Atensor([[1.2933e-03, 1.0406e-03, 2.3323e-02,  ..., 7.1834e-02, 1.0888e-03,\n",
            "         3.3892e-02],\n",
            "        [1.3369e-03, 8.4340e-04, 1.0114e-02,  ..., 2.5474e-02, 1.1188e-03,\n",
            "         1.2889e-02],\n",
            "        [1.4607e-03, 9.5650e-04, 9.3124e-03,  ..., 2.8672e-02, 1.2546e-03,\n",
            "         2.7494e-02],\n",
            "        ...,\n",
            "        [1.3331e-03, 8.9159e-04, 8.4638e-03,  ..., 3.6535e-02, 1.0541e-03,\n",
            "         1.6912e-02],\n",
            "        [1.1705e-03, 9.6441e-04, 8.6886e-02,  ..., 5.7644e-02, 1.0542e-03,\n",
            "         3.8536e-02],\n",
            "        [2.2984e-03, 2.5169e-03, 8.4426e-01,  ..., 8.8269e-02, 2.2644e-03,\n",
            "         3.7614e-02]])\n",
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 1. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 1. ... 0. 0. 0.]]\n",
            "                                      \n",
            "\u001b[A{'eval_loss': 0.14591890573501587, 'eval_hier_f1': 0.3578076525336091, 'eval_hier_precision': 0.807153965785381, 'eval_hier_recall': 0.22984942426926483, 'eval_runtime': 2.7974, 'eval_samples_per_second': 178.738, 'eval_steps_per_second': 22.521, 'epoch': 1.0}\n",
            " 20% 875/4375 [03:46<14:32,  4.01it/s]\n",
            "100% 63/63 [00:02<00:00, 19.05it/s]\u001b[A\n",
            "{'loss': 0.1432, 'learning_rate': 3.0085714285714287e-05, 'epoch': 1.14}\n",
            "{'loss': 0.1287, 'learning_rate': 2.562857142857143e-05, 'epoch': 1.71}\n",
            " 40% 1750/4375 [08:01<11:40,  3.75it/s]\n",
            "  0% 0/63 [00:00<?, ?it/s]\u001b[A\n",
            "  6% 4/63 [00:00<00:01, 32.61it/s]\u001b[A\n",
            " 13% 8/63 [00:00<00:02, 25.25it/s]\u001b[A\n",
            " 17% 11/63 [00:00<00:02, 23.52it/s]\u001b[A\n",
            " 24% 15/63 [00:00<00:01, 26.93it/s]\u001b[A\n",
            " 29% 18/63 [00:00<00:01, 25.45it/s]\u001b[A\n",
            " 33% 21/63 [00:00<00:01, 25.10it/s]\u001b[A\n",
            " 38% 24/63 [00:00<00:01, 23.52it/s]\u001b[A\n",
            " 43% 27/63 [00:01<00:01, 23.01it/s]\u001b[A\n",
            " 49% 31/63 [00:01<00:01, 27.18it/s]\u001b[A\n",
            " 54% 34/63 [00:01<00:01, 27.45it/s]\u001b[A\n",
            " 59% 37/63 [00:01<00:01, 24.69it/s]\u001b[A\n",
            " 63% 40/63 [00:01<00:00, 25.30it/s]\u001b[A\n",
            " 70% 44/63 [00:01<00:00, 26.18it/s]\u001b[A\n",
            " 75% 47/63 [00:01<00:00, 23.74it/s]\u001b[A\n",
            " 79% 50/63 [00:02<00:00, 22.69it/s]\u001b[A\n",
            " 84% 53/63 [00:02<00:00, 21.10it/s]\u001b[A\n",
            " 89% 56/63 [00:02<00:00, 20.48it/s]\u001b[A\n",
            " 94% 59/63 [00:02<00:00, 19.72it/s]\u001b[A\n",
            " 98% 62/63 [00:02<00:00, 19.34it/s]\u001b[Atensor([[1.7732e-03, 1.7179e-03, 1.8240e-02,  ..., 1.6514e-01, 1.6472e-03,\n",
            "         5.5491e-02],\n",
            "        [3.9373e-04, 2.9925e-04, 1.0914e-02,  ..., 1.8386e-02, 3.3240e-04,\n",
            "         6.3572e-03],\n",
            "        [6.4226e-04, 6.0473e-04, 6.6503e-03,  ..., 5.3341e-02, 4.8259e-04,\n",
            "         1.5072e-02],\n",
            "        ...,\n",
            "        [7.7511e-04, 4.1614e-04, 3.7822e-03,  ..., 5.3109e-02, 4.4101e-04,\n",
            "         1.2323e-02],\n",
            "        [4.0403e-04, 3.6099e-04, 1.0207e-01,  ..., 3.4460e-02, 3.6590e-04,\n",
            "         1.4553e-02],\n",
            "        [1.4924e-03, 1.8695e-03, 9.4595e-01,  ..., 1.8192e-01, 1.5283e-03,\n",
            "         2.4177e-02]])\n",
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 1. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 1. ... 0. 0. 0.]]\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 0.13499754667282104, 'eval_hier_f1': 0.40577806959947466, 'eval_hier_precision': 0.7842639593908629, 'eval_hier_recall': 0.2736935341009743, 'eval_runtime': 2.7482, 'eval_samples_per_second': 181.936, 'eval_steps_per_second': 22.924, 'epoch': 2.0}\n",
            " 40% 1750/4375 [08:04<11:40,  3.75it/s]\n",
            "100% 63/63 [00:02<00:00, 19.34it/s]\u001b[A\n",
            "{'loss': 0.1207, 'learning_rate': 2.117142857142857e-05, 'epoch': 2.29}\n",
            "{'loss': 0.109, 'learning_rate': 1.6714285714285713e-05, 'epoch': 2.86}\n",
            " 60% 2625/4375 [12:24<07:35,  3.84it/s]\n",
            "  0% 0/63 [00:00<?, ?it/s]\u001b[A\n",
            "  6% 4/63 [00:00<00:01, 32.56it/s]\u001b[A\n",
            " 13% 8/63 [00:00<00:02, 25.61it/s]\u001b[A\n",
            " 17% 11/63 [00:00<00:02, 23.87it/s]\u001b[A\n",
            " 24% 15/63 [00:00<00:01, 27.32it/s]\u001b[A\n",
            " 29% 18/63 [00:00<00:01, 25.51it/s]\u001b[A\n",
            " 33% 21/63 [00:00<00:01, 24.84it/s]\u001b[A\n",
            " 38% 24/63 [00:00<00:01, 23.32it/s]\u001b[A\n",
            " 43% 27/63 [00:01<00:01, 22.79it/s]\u001b[A\n",
            " 49% 31/63 [00:01<00:01, 26.98it/s]\u001b[A\n",
            " 54% 34/63 [00:01<00:01, 26.77it/s]\u001b[A\n",
            " 59% 37/63 [00:01<00:01, 24.12it/s]\u001b[A\n",
            " 63% 40/63 [00:01<00:00, 24.72it/s]\u001b[A\n",
            " 70% 44/63 [00:01<00:00, 25.68it/s]\u001b[A\n",
            " 75% 47/63 [00:01<00:00, 23.21it/s]\u001b[A\n",
            " 79% 50/63 [00:02<00:00, 22.06it/s]\u001b[A\n",
            " 84% 53/63 [00:02<00:00, 20.51it/s]\u001b[A\n",
            " 89% 56/63 [00:02<00:00, 19.80it/s]\u001b[A\n",
            " 94% 59/63 [00:02<00:00, 18.97it/s]\u001b[A\n",
            " 97% 61/63 [00:02<00:00, 18.74it/s]\u001b[Atensor([[1.6006e-03, 1.6757e-03, 1.4035e-02,  ..., 1.9510e-01, 1.4566e-03,\n",
            "         4.4535e-02],\n",
            "        [1.8155e-04, 1.3728e-04, 6.2672e-03,  ..., 1.5357e-02, 1.5056e-04,\n",
            "         3.5541e-03],\n",
            "        [7.2951e-04, 7.4640e-04, 5.8133e-03,  ..., 6.6155e-02, 5.2004e-04,\n",
            "         2.2164e-02],\n",
            "        ...,\n",
            "        [5.3599e-04, 2.2035e-04, 1.7184e-03,  ..., 5.1896e-02, 2.5988e-04,\n",
            "         5.4432e-03],\n",
            "        [9.9833e-04, 8.2208e-04, 1.6260e-01,  ..., 2.3890e-02, 8.9266e-04,\n",
            "         1.9345e-02],\n",
            "        [1.3964e-03, 1.7431e-03, 9.8650e-01,  ..., 1.9142e-01, 1.5797e-03,\n",
            "         2.3368e-02]])\n",
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 1. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 1. ... 0. 0. 0.]]\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 0.13367511332035065, 'eval_hier_f1': 0.5223542727787212, 'eval_hier_precision': 0.7233542319749217, 'eval_hier_recall': 0.4087688219663419, 'eval_runtime': 2.8156, 'eval_samples_per_second': 177.581, 'eval_steps_per_second': 22.375, 'epoch': 3.0}\n",
            " 60% 2625/4375 [12:27<07:35,  3.84it/s]\n",
            "100% 63/63 [00:02<00:00, 18.74it/s]\u001b[A\n",
            "{'loss': 0.0964, 'learning_rate': 1.2257142857142856e-05, 'epoch': 3.43}\n",
            "{'loss': 0.0898, 'learning_rate': 7.8e-06, 'epoch': 4.0}\n",
            " 80% 3500/4375 [16:33<03:49,  3.82it/s]\n",
            "  0% 0/63 [00:00<?, ?it/s]\u001b[A\n",
            "  6% 4/63 [00:00<00:01, 33.64it/s]\u001b[A\n",
            " 13% 8/63 [00:00<00:02, 25.83it/s]\u001b[A\n",
            " 17% 11/63 [00:00<00:02, 23.85it/s]\u001b[A\n",
            " 24% 15/63 [00:00<00:01, 27.34it/s]\u001b[A\n",
            " 29% 18/63 [00:00<00:01, 25.61it/s]\u001b[A\n",
            " 33% 21/63 [00:00<00:01, 24.82it/s]\u001b[A\n",
            " 38% 24/63 [00:00<00:01, 23.19it/s]\u001b[A\n",
            " 43% 27/63 [00:01<00:01, 22.65it/s]\u001b[A\n",
            " 49% 31/63 [00:01<00:01, 26.82it/s]\u001b[A\n",
            " 54% 34/63 [00:01<00:01, 27.03it/s]\u001b[A\n",
            " 59% 37/63 [00:01<00:01, 24.29it/s]\u001b[A\n",
            " 63% 40/63 [00:01<00:00, 24.88it/s]\u001b[A\n",
            " 70% 44/63 [00:01<00:00, 25.78it/s]\u001b[A\n",
            " 75% 47/63 [00:01<00:00, 23.44it/s]\u001b[A\n",
            " 79% 50/63 [00:02<00:00, 22.34it/s]\u001b[A\n",
            " 84% 53/63 [00:02<00:00, 20.78it/s]\u001b[A\n",
            " 89% 56/63 [00:02<00:00, 20.12it/s]\u001b[A\n",
            " 94% 59/63 [00:02<00:00, 19.31it/s]\u001b[A\n",
            " 97% 61/63 [00:02<00:00, 19.12it/s]\u001b[Atensor([[1.6065e-03, 1.4878e-03, 1.3296e-02,  ..., 2.1551e-01, 1.5156e-03,\n",
            "         2.3578e-02],\n",
            "        [7.4402e-05, 5.1728e-05, 2.9940e-03,  ..., 8.5399e-03, 6.0463e-05,\n",
            "         2.6044e-03],\n",
            "        [4.3150e-04, 4.3102e-04, 3.8046e-03,  ..., 6.1483e-02, 2.8571e-04,\n",
            "         1.4638e-02],\n",
            "        ...,\n",
            "        [2.3016e-04, 8.8812e-05, 1.7926e-03,  ..., 2.5466e-02, 1.2015e-04,\n",
            "         3.7470e-03],\n",
            "        [2.5675e-04, 1.9469e-04, 1.0902e-02,  ..., 1.3015e-02, 2.3234e-04,\n",
            "         1.3166e-02],\n",
            "        [1.0446e-03, 1.0741e-03, 9.8160e-01,  ..., 1.9193e-01, 1.3282e-03,\n",
            "         1.7410e-02]])\n",
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 1. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 1. ... 0. 0. 0.]]\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 0.13078932464122772, 'eval_hier_f1': 0.5484318623369414, 'eval_hier_precision': 0.7345724907063197, 'eval_hier_recall': 0.437555358724535, 'eval_runtime': 2.7747, 'eval_samples_per_second': 180.201, 'eval_steps_per_second': 22.705, 'epoch': 4.0}\n",
            " 80% 3500/4375 [16:36<03:49,  3.82it/s]\n",
            "100% 63/63 [00:02<00:00, 19.12it/s]\u001b[A\n",
            "{'loss': 0.0777, 'learning_rate': 3.3428571428571427e-06, 'epoch': 4.57}\n",
            "100% 4375/4375 [20:59<00:00,  3.72it/s]\n",
            "  0% 0/63 [00:00<?, ?it/s]\u001b[A\n",
            "  6% 4/63 [00:00<00:01, 33.59it/s]\u001b[A\n",
            " 13% 8/63 [00:00<00:02, 25.62it/s]\u001b[A\n",
            " 17% 11/63 [00:00<00:02, 23.94it/s]\u001b[A\n",
            " 24% 15/63 [00:00<00:01, 27.20it/s]\u001b[A\n",
            " 29% 18/63 [00:00<00:01, 25.40it/s]\u001b[A\n",
            " 33% 21/63 [00:00<00:01, 24.65it/s]\u001b[A\n",
            " 38% 24/63 [00:00<00:01, 22.88it/s]\u001b[A\n",
            " 43% 27/63 [00:01<00:01, 22.50it/s]\u001b[A\n",
            " 51% 32/63 [00:01<00:01, 26.80it/s]\u001b[A\n",
            " 56% 35/63 [00:01<00:01, 26.17it/s]\u001b[A\n",
            " 60% 38/63 [00:01<00:01, 24.61it/s]\u001b[A\n",
            " 65% 41/63 [00:01<00:00, 25.03it/s]\u001b[A\n",
            " 70% 44/63 [00:01<00:00, 25.75it/s]\u001b[A\n",
            " 75% 47/63 [00:01<00:00, 23.17it/s]\u001b[A\n",
            " 79% 50/63 [00:02<00:00, 21.99it/s]\u001b[A\n",
            " 84% 53/63 [00:02<00:00, 20.55it/s]\u001b[A\n",
            " 89% 56/63 [00:02<00:00, 19.89it/s]\u001b[A\n",
            " 94% 59/63 [00:02<00:00, 19.15it/s]\u001b[A\n",
            " 97% 61/63 [00:02<00:00, 18.95it/s]\u001b[Atensor([[1.9530e-03, 1.7708e-03, 1.2194e-02,  ..., 2.3621e-01, 1.7825e-03,\n",
            "         2.3145e-02],\n",
            "        [5.6967e-05, 4.0694e-05, 3.3694e-03,  ..., 7.5430e-03, 4.6074e-05,\n",
            "         2.3275e-03],\n",
            "        [3.0205e-04, 2.9235e-04, 5.1084e-03,  ..., 3.7949e-02, 1.8750e-04,\n",
            "         1.6343e-02],\n",
            "        ...,\n",
            "        [2.0899e-04, 8.2086e-05, 2.5572e-03,  ..., 2.4343e-02, 1.1972e-04,\n",
            "         3.4145e-03],\n",
            "        [3.4092e-04, 2.4785e-04, 9.7418e-03,  ..., 7.3372e-03, 3.1919e-04,\n",
            "         1.6796e-02],\n",
            "        [1.2994e-03, 1.3141e-03, 9.7985e-01,  ..., 2.4458e-01, 1.6270e-03,\n",
            "         1.8649e-02]])\n",
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 1. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 1. ... 0. 0. 0.]]\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 0.13241156935691833, 'eval_hier_f1': 0.5622362869198313, 'eval_hier_precision': 0.6949152542372882, 'eval_hier_recall': 0.4720992028343667, 'eval_runtime': 2.7922, 'eval_samples_per_second': 179.072, 'eval_steps_per_second': 22.563, 'epoch': 5.0}\n",
            "100% 4375/4375 [21:02<00:00,  3.72it/s]\n",
            "100% 63/63 [00:02<00:00, 18.95it/s]\u001b[A\n",
            "{'train_runtime': 1288.2998, 'train_samples_per_second': 27.168, 'train_steps_per_second': 3.396, 'train_loss': 0.114880515398298, 'epoch': 5.0}\n",
            "100% 4375/4375 [21:28<00:00,  3.40it/s]\n",
            " 98% 62/63 [00:02<00:00, 19.34it/s]tensor([[1.9530e-03, 1.7708e-03, 1.2194e-02,  ..., 2.3621e-01, 1.7825e-03,\n",
            "         2.3145e-02],\n",
            "        [5.6967e-05, 4.0694e-05, 3.3694e-03,  ..., 7.5430e-03, 4.6074e-05,\n",
            "         2.3275e-03],\n",
            "        [3.0205e-04, 2.9235e-04, 5.1084e-03,  ..., 3.7949e-02, 1.8750e-04,\n",
            "         1.6343e-02],\n",
            "        ...,\n",
            "        [2.0899e-04, 8.2086e-05, 2.5572e-03,  ..., 2.4343e-02, 1.1972e-04,\n",
            "         3.4145e-03],\n",
            "        [3.4092e-04, 2.4785e-04, 9.7418e-03,  ..., 7.3372e-03, 3.1919e-04,\n",
            "         1.6796e-02],\n",
            "        [1.2994e-03, 1.3141e-03, 9.7985e-01,  ..., 2.4458e-01, 1.6270e-03,\n",
            "         1.8649e-02]])\n",
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 1. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 1. ... 0. 0. 0.]]\n",
            "100% 63/63 [00:02<00:00, 23.17it/s]\n",
            "(dev_set) Evaluation results: {\n",
            "    \"eval_loss\": 0.13241156935691833,\n",
            "    \"eval_hier_f1\": 0.5622362869198313,\n",
            "    \"eval_hier_precision\": 0.6949152542372882,\n",
            "    \"eval_hier_recall\": 0.4720992028343667,\n",
            "    \"eval_runtime\": 2.7854,\n",
            "    \"eval_samples_per_second\": 179.508,\n",
            "    \"eval_steps_per_second\": 22.618,\n",
            "    \"epoch\": 5.0\n",
            "}\n",
            "Saving fine-tuned model to /gdrive/My Drive/projects/bambas/fine_tuning_with_class/jhu-clsp-bernice-semeval2024-dev-labeled-classifier\n",
            "Prediction on test_set\n",
            "#0: 100% 32/32 [00:00<00:00, 100.96ba/s]\n",
            "\n",
            "#1:   0% 0/32 [00:00<?, ?ba/s]\u001b[A\n",
            "#1:  25% 8/32 [00:00<00:00, 78.94ba/s]\u001b[A\n",
            "\n",
            "\n",
            "#3:   0% 0/32 [00:00<?, ?ba/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "#2:   0% 0/32 [00:00<?, ?ba/s]\u001b[A\u001b[A\n",
            "#1: 100% 32/32 [00:00<00:00, 113.16ba/s]\n",
            "\n",
            "\n",
            "\n",
            "#3:  25% 8/32 [00:00<00:00, 76.70ba/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "#2:  28% 9/32 [00:00<00:00, 85.13ba/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "#3:  72% 23/32 [00:00<00:00, 114.22ba/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "#2: 100% 32/32 [00:00<00:00, 121.72ba/s]\n",
            "#3: 100% 32/32 [00:00<00:00, 112.35ba/s]\n",
            "Batch no. 1. Transferring to device\n",
            "Batch no. 2. Transferring to device\n",
            "Batch no. 3. Transferring to device\n",
            "Batch no. 4. Transferring to device\n",
            "Batch no. 5. Transferring to device\n",
            "Batch no. 6. Transferring to device\n",
            "Batch no. 7. Transferring to device\n",
            "Batch no. 8. Transferring to device\n",
            "Batch no. 9. Transferring to device\n",
            "Batch no. 10. Transferring to device\n",
            "Batch no. 11. Transferring to device\n",
            "Batch no. 12. Transferring to device\n",
            "Batch no. 13. Transferring to device\n",
            "Batch no. 14. Transferring to device\n",
            "Batch no. 15. Transferring to device\n",
            "Batch no. 16. Transferring to device\n",
            "Batch no. 17. Transferring to device\n",
            "Batch no. 18. Transferring to device\n",
            "Batch no. 19. Transferring to device\n",
            "Batch no. 20. Transferring to device\n",
            "Batch no. 21. Transferring to device\n",
            "Batch no. 22. Transferring to device\n",
            "Batch no. 23. Transferring to device\n",
            "Batch no. 24. Transferring to device\n",
            "Batch no. 25. Transferring to device\n",
            "Batch no. 26. Transferring to device\n",
            "Batch no. 27. Transferring to device\n",
            "Batch no. 28. Transferring to device\n",
            "Batch no. 29. Transferring to device\n",
            "Batch no. 30. Transferring to device\n",
            "Batch no. 31. Transferring to device\n",
            "Batch no. 32. Transferring to device\n",
            "Batch no. 33. Transferring to device\n",
            "Batch no. 34. Transferring to device\n",
            "Batch no. 35. Transferring to device\n",
            "Batch no. 36. Transferring to device\n",
            "Batch no. 37. Transferring to device\n",
            "Batch no. 38. Transferring to device\n",
            "Batch no. 39. Transferring to device\n",
            "Batch no. 40. Transferring to device\n",
            "Batch no. 41. Transferring to device\n",
            "Batch no. 42. Transferring to device\n",
            "Batch no. 43. Transferring to device\n",
            "Batch no. 44. Transferring to device\n",
            "Batch no. 45. Transferring to device\n",
            "Batch no. 46. Transferring to device\n",
            "Batch no. 47. Transferring to device\n",
            "Batch no. 48. Transferring to device\n",
            "Batch no. 49. Transferring to device\n",
            "Batch no. 50. Transferring to device\n",
            "Batch no. 51. Transferring to device\n",
            "Batch no. 52. Transferring to device\n",
            "Batch no. 53. Transferring to device\n",
            "Batch no. 54. Transferring to device\n",
            "Batch no. 55. Transferring to device\n",
            "Batch no. 56. Transferring to device\n",
            "Batch no. 57. Transferring to device\n",
            "Batch no. 58. Transferring to device\n",
            "Batch no. 59. Transferring to device\n",
            "Batch no. 60. Transferring to device\n",
            "Batch no. 61. Transferring to device\n",
            "Batch no. 62. Transferring to device\n",
            "Batch no. 63. Transferring to device\n",
            "Batch no. 64. Transferring to device\n",
            "Batch no. 65. Transferring to device\n",
            "Batch no. 66. Transferring to device\n",
            "Batch no. 67. Transferring to device\n",
            "Batch no. 68. Transferring to device\n",
            "Batch no. 69. Transferring to device\n",
            "Batch no. 70. Transferring to device\n",
            "Batch no. 71. Transferring to device\n",
            "Batch no. 72. Transferring to device\n",
            "Batch no. 73. Transferring to device\n",
            "Batch no. 74. Transferring to device\n",
            "Batch no. 75. Transferring to device\n",
            "Batch no. 76. Transferring to device\n",
            "Batch no. 77. Transferring to device\n",
            "Batch no. 78. Transferring to device\n",
            "Batch no. 79. Transferring to device\n",
            "Batch no. 80. Transferring to device\n",
            "Batch no. 81. Transferring to device\n",
            "Batch no. 82. Transferring to device\n",
            "Batch no. 83. Transferring to device\n",
            "Batch no. 84. Transferring to device\n",
            "Batch no. 85. Transferring to device\n",
            "Batch no. 86. Transferring to device\n",
            "Batch no. 87. Transferring to device\n",
            "Batch no. 88. Transferring to device\n",
            "Batch no. 89. Transferring to device\n",
            "Batch no. 90. Transferring to device\n",
            "Batch no. 91. Transferring to device\n",
            "Batch no. 92. Transferring to device\n",
            "Batch no. 93. Transferring to device\n",
            "Batch no. 94. Transferring to device\n",
            "Batch no. 95. Transferring to device\n",
            "Batch no. 96. Transferring to device\n",
            "Batch no. 97. Transferring to device\n",
            "Batch no. 98. Transferring to device\n",
            "Batch no. 99. Transferring to device\n",
            "Batch no. 100. Transferring to device\n",
            "Batch no. 101. Transferring to device\n",
            "Batch no. 102. Transferring to device\n",
            "Batch no. 103. Transferring to device\n",
            "Batch no. 104. Transferring to device\n",
            "Batch no. 105. Transferring to device\n",
            "Batch no. 106. Transferring to device\n",
            "Batch no. 107. Transferring to device\n",
            "Batch no. 108. Transferring to device\n",
            "Batch no. 109. Transferring to device\n",
            "Batch no. 110. Transferring to device\n",
            "Batch no. 111. Transferring to device\n",
            "Batch no. 112. Transferring to device\n",
            "Batch no. 113. Transferring to device\n",
            "Batch no. 114. Transferring to device\n",
            "Batch no. 115. Transferring to device\n",
            "Batch no. 116. Transferring to device\n",
            "Batch no. 117. Transferring to device\n",
            "Batch no. 118. Transferring to device\n",
            "Batch no. 119. Transferring to device\n",
            "Batch no. 120. Transferring to device\n",
            "Batch no. 121. Transferring to device\n",
            "Batch no. 122. Transferring to device\n",
            "Batch no. 123. Transferring to device\n",
            "Batch no. 124. Transferring to device\n",
            "Batch no. 125. Transferring to device\n",
            "\n",
            "Test set:\n",
            "\tPrecision: 0.7325933400605449\n",
            "\tRecall: 0.4532778355879292\n",
            "\tF1: 0.5600411416816662\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!PYTHONPATH=\"/gdrive/My Drive/projects/bambas\" python -m src.fine_tuning_with_class \\\n",
        "  --model jhu-clsp/bernice \\\n",
        "  --dataset semeval2024_test_unlabeled \\\n",
        "  --fine_tuned_name jhu-clsp-bernice-semeval2024-test-unlabeled-classifier \\\n",
        "  --batch_size 8 \\\n",
        "  --save_strategy epoch \\\n",
        "  --lr 3.9e-5 \\\n",
        "  --epochs 5 \\\n",
        "  --save_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9hTiTJe8qpg",
        "outputId": "a7a9bcea-74ad-4434-9f92-bcea5a5a9852"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-02-14 23:53:36.813982: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-02-14 23:53:36.814027: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-02-14 23:53:36.815352: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-02-14 23:53:37.970607: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Running on Google Colab, workdir: /gdrive/My Drive/projects/bambas\n",
            "Running on Google Colab, workdir: /gdrive/My Drive/projects/bambas\n",
            "Running on Google Colab, workdir: /gdrive/My Drive/projects/bambas\n",
            "Running on Google Colab, workdir: /gdrive/My Drive/projects/bambas\n",
            "Running on Google Colab, workdir: /gdrive/My Drive/projects/bambas\n",
            "Running on Google Colab, workdir: /gdrive/My Drive/projects/bambas\n",
            "Arguments: Namespace(model='jhu-clsp/bernice', dataset='semeval2024_test_unlabeled', fine_tuned_name='jhu-clsp-bernice-semeval2024-test-unlabeled-classifier', batch_size=8, max_length=128, lr=3.9e-05, weight_decay=0.001, save_model=True, concat_train_dev=False, hypsearch=False, hpsearch_min=3.9e-05, hpsearch_max=3.9e-05, n_trials=10, epochs=5, push_model_to_hf_hub=False, save_strategy='epoch')\n",
            "Using device: {'': 0}\n",
            "#0:  18% 42/235 [00:00<00:01, 101.05ba/s]\n",
            "#1:   0% 0/235 [00:00<?, ?ba/s]\u001b[A\n",
            "#0:  23% 53/235 [00:00<00:02, 89.09ba/s] \n",
            "#0:  28% 66/235 [00:00<00:01, 100.81ba/s]\n",
            "#0:  34% 80/235 [00:00<00:01, 110.42ba/s]\n",
            "#0:  40% 93/235 [00:00<00:01, 115.57ba/s]\n",
            "\n",
            "#2:   0% 0/235 [00:00<?, ?ba/s]\u001b[A\u001b[A\n",
            "#0:  45% 106/235 [00:00<00:01, 115.74ba/s]\n",
            "\n",
            "#2:   3% 8/235 [00:00<00:02, 77.98ba/s]\u001b[A\u001b[A\n",
            "#0:  51% 120/235 [00:01<00:00, 119.32ba/s]\n",
            "\n",
            "#2:   9% 22/235 [00:00<00:02, 103.45ba/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "#3:   0% 0/235 [00:00<?, ?ba/s]\u001b[A\u001b[A\u001b[A\n",
            "#0:  57% 133/235 [00:01<00:00, 113.81ba/s]\n",
            "\n",
            "#2:  14% 33/235 [00:00<00:01, 105.25ba/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "#3:   5% 12/235 [00:00<00:01, 116.90ba/s]\u001b[A\u001b[A\u001b[A\n",
            "#0:  63% 148/235 [00:01<00:00, 123.73ba/s]\n",
            "\n",
            "#2:  20% 48/235 [00:00<00:01, 121.07ba/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "#3:  10% 24/235 [00:00<00:01, 115.83ba/s]\u001b[A\u001b[A\u001b[A\n",
            "#0:  69% 161/235 [00:01<00:00, 115.96ba/s]\n",
            "\n",
            "#2:  31% 72/235 [00:00<00:01, 158.03ba/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "#3:  15% 36/235 [00:00<00:01, 109.99ba/s]\u001b[A\u001b[A\u001b[A\n",
            "#0:  74% 175/235 [00:01<00:00, 119.27ba/s]\n",
            "\n",
            "#2:  37% 88/235 [00:00<00:01, 142.63ba/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "#3:  20% 48/235 [00:00<00:01, 108.99ba/s]\u001b[A\u001b[A\u001b[A\n",
            "#0:  80% 188/235 [00:01<00:00, 120.69ba/s]\n",
            "\n",
            "\n",
            "#3:  25% 59/235 [00:00<00:01, 104.22ba/s]\u001b[A\u001b[A\u001b[A\n",
            "#1:  64% 151/235 [00:01<00:00, 109.43ba/s]\u001b[A\n",
            "\n",
            "#0:  86% 201/235 [00:01<00:00, 108.03ba/s]\n",
            "\n",
            "\n",
            "#3:  30% 70/235 [00:00<00:01, 93.69ba/s] \u001b[A\u001b[A\u001b[A\n",
            "#1:  69% 163/235 [00:01<00:00, 99.42ba/s] \u001b[A\n",
            "\n",
            "#0:  91% 213/235 [00:02<00:00, 93.78ba/s] \n",
            "\n",
            "\n",
            "#3:  34% 80/235 [00:00<00:01, 84.86ba/s]\u001b[A\u001b[A\u001b[A\n",
            "#1:  74% 174/235 [00:01<00:00, 91.72ba/s]\u001b[A\n",
            "\n",
            "#0:  95% 223/235 [00:02<00:00, 87.37ba/s]\n",
            "\n",
            "\n",
            "#3:  38% 89/235 [00:00<00:01, 77.96ba/s]\u001b[A\u001b[A\u001b[A\n",
            "#1:  78% 184/235 [00:01<00:00, 83.84ba/s]\u001b[A\n",
            "\n",
            "#2:  60% 140/235 [00:01<00:01, 88.56ba/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "#0:  99% 233/235 [00:02<00:00, 80.35ba/s]\n",
            "#0: 100% 235/235 [00:02<00:00, 101.34ba/s]\n",
            "\n",
            "\n",
            "\n",
            "#3:  45% 105/235 [00:01<00:01, 76.55ba/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "#2:  64% 150/235 [00:01<00:01, 83.18ba/s]\u001b[A\u001b[A\n",
            "#1:  86% 202/235 [00:02<00:00, 76.96ba/s]\u001b[A\n",
            "\n",
            "\n",
            "#3:  48% 113/235 [00:01<00:01, 71.43ba/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "#2:  68% 159/235 [00:01<00:00, 76.08ba/s]\u001b[A\u001b[A\n",
            "#1:  89% 210/235 [00:02<00:00, 74.74ba/s]\u001b[A\n",
            "\n",
            "\n",
            "#3:  51% 121/235 [00:01<00:01, 69.73ba/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "#2:  71% 167/235 [00:01<00:00, 71.97ba/s]\u001b[A\u001b[A\n",
            "#1:  93% 218/235 [00:02<00:00, 73.27ba/s]\u001b[A\n",
            "\n",
            "\n",
            "#3:  55% 129/235 [00:01<00:01, 71.24ba/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "#2:  75% 177/235 [00:01<00:00, 77.74ba/s]\u001b[A\u001b[A\n",
            "#1:  96% 226/235 [00:02<00:00, 73.25ba/s]\u001b[A\n",
            "\n",
            "\n",
            "#3:  58% 137/235 [00:01<00:01, 69.98ba/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "#2:  80% 187/235 [00:01<00:00, 81.73ba/s]\u001b[A\u001b[A\n",
            "#1: 100% 235/235 [00:02<00:00, 94.35ba/s]\n",
            "\n",
            "\n",
            "\n",
            "#3:  62% 145/235 [00:01<00:01, 72.32ba/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "#2:  83% 196/235 [00:02<00:00, 81.55ba/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "#3:  65% 153/235 [00:01<00:01, 67.46ba/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "#2:  87% 205/235 [00:02<00:00, 75.92ba/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "#3:  69% 162/235 [00:02<00:01, 72.20ba/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "#2:  91% 213/235 [00:02<00:00, 72.52ba/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "#3:  74% 174/235 [00:02<00:00, 83.47ba/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "#2:  95% 224/235 [00:02<00:00, 79.27ba/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "#3:  78% 183/235 [00:02<00:00, 82.47ba/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "#2: 100% 235/235 [00:02<00:00, 92.17ba/s]\n",
            "\n",
            "\n",
            "\n",
            "#3:  82% 192/235 [00:02<00:00, 83.91ba/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "#3:  86% 201/235 [00:02<00:00, 82.98ba/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "#3:  89% 210/235 [00:02<00:00, 78.62ba/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "#3:  94% 220/235 [00:02<00:00, 81.45ba/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "#3: 100% 235/235 [00:02<00:00, 82.04ba/s]\n",
            "#0: 100% 32/32 [00:00<00:00, 105.37ba/s]\n",
            "\n",
            "#1:   0% 0/32 [00:00<?, ?ba/s]\u001b[A\n",
            "\n",
            "#2:   0% 0/32 [00:00<?, ?ba/s]\u001b[A\u001b[A\n",
            "#1:  19% 6/32 [00:00<00:00, 55.10ba/s]\u001b[A\n",
            "\n",
            "\n",
            "#3:   0% 0/32 [00:00<?, ?ba/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "#2:  28% 9/32 [00:00<00:00, 84.01ba/s]\u001b[A\u001b[A\n",
            "#1:  56% 18/32 [00:00<00:00, 82.31ba/s]\u001b[A\n",
            "\n",
            "\n",
            "#2: 100% 32/32 [00:00<00:00, 155.88ba/s]\n",
            "\n",
            "#1: 100% 32/32 [00:00<00:00, 96.82ba/s] \n",
            "\n",
            "\n",
            "\n",
            "#3: 100% 32/32 [00:00<00:00, 105.12ba/s]\n",
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at jhu-clsp/bernice and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "  0% 0/4690 [00:00<?, ?it/s]You're using a XLMRobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "{'loss': 0.1837, 'learning_rate': 3.484221748400853e-05, 'epoch': 0.53}\n",
            " 20% 938/4690 [04:06<15:19,  4.08it/s]\n",
            "  0% 0/125 [00:00<?, ?it/s]\u001b[A\n",
            "  3% 4/125 [00:00<00:04, 26.45it/s]\u001b[A\n",
            "  6% 7/125 [00:00<00:04, 25.08it/s]\u001b[A\n",
            "  8% 10/125 [00:00<00:04, 24.86it/s]\u001b[A\n",
            " 10% 13/125 [00:00<00:04, 22.59it/s]\u001b[A\n",
            " 13% 16/125 [00:00<00:04, 22.76it/s]\u001b[A\n",
            " 15% 19/125 [00:00<00:04, 21.43it/s]\u001b[A\n",
            " 18% 23/125 [00:00<00:04, 25.38it/s]\u001b[A\n",
            " 21% 26/125 [00:01<00:03, 25.68it/s]\u001b[A\n",
            " 23% 29/125 [00:01<00:03, 25.30it/s]\u001b[A\n",
            " 26% 32/125 [00:01<00:03, 25.25it/s]\u001b[A\n",
            " 29% 36/125 [00:01<00:03, 27.08it/s]\u001b[A\n",
            " 31% 39/125 [00:01<00:03, 25.34it/s]\u001b[A\n",
            " 34% 42/125 [00:01<00:03, 24.53it/s]\u001b[A\n",
            " 37% 46/125 [00:01<00:03, 26.16it/s]\u001b[A\n",
            " 39% 49/125 [00:01<00:03, 24.66it/s]\u001b[A\n",
            " 42% 52/125 [00:02<00:03, 22.88it/s]\u001b[A\n",
            " 44% 55/125 [00:02<00:03, 22.47it/s]\u001b[A\n",
            " 46% 58/125 [00:02<00:03, 20.79it/s]\u001b[A\n",
            " 49% 61/125 [00:02<00:03, 21.26it/s]\u001b[A\n",
            " 51% 64/125 [00:02<00:03, 20.25it/s]\u001b[A\n",
            " 54% 67/125 [00:02<00:02, 19.59it/s]\u001b[A\n",
            " 56% 70/125 [00:03<00:02, 20.64it/s]\u001b[A\n",
            " 58% 73/125 [00:03<00:02, 19.75it/s]\u001b[A\n",
            " 61% 76/125 [00:03<00:02, 20.46it/s]\u001b[A\n",
            " 63% 79/125 [00:03<00:02, 20.13it/s]\u001b[A\n",
            " 66% 82/125 [00:03<00:02, 20.81it/s]\u001b[A\n",
            " 68% 85/125 [00:03<00:01, 21.39it/s]\u001b[A\n",
            " 70% 88/125 [00:03<00:01, 21.09it/s]\u001b[A\n",
            " 73% 91/125 [00:04<00:01, 20.56it/s]\u001b[A\n",
            " 75% 94/125 [00:04<00:01, 20.51it/s]\u001b[A\n",
            " 78% 97/125 [00:04<00:01, 22.15it/s]\u001b[A\n",
            " 80% 100/125 [00:04<00:01, 21.86it/s]\u001b[A\n",
            " 82% 103/125 [00:04<00:01, 21.60it/s]\u001b[A\n",
            " 85% 106/125 [00:04<00:00, 22.78it/s]\u001b[A\n",
            " 87% 109/125 [00:04<00:00, 21.44it/s]\u001b[A\n",
            " 90% 112/125 [00:04<00:00, 22.18it/s]\u001b[A\n",
            " 92% 115/125 [00:05<00:00, 22.86it/s]\u001b[A\n",
            " 94% 118/125 [00:05<00:00, 22.27it/s]\u001b[A\n",
            " 97% 121/125 [00:05<00:00, 23.74it/s]\u001b[A\n",
            " 99% 124/125 [00:05<00:00, 22.48it/s]\u001b[Atensor([[0.0018, 0.0020, 0.0201,  ..., 0.0652, 0.0024, 0.0109],\n",
            "        [0.0033, 0.0025, 0.0492,  ..., 0.1275, 0.0039, 0.0517],\n",
            "        [0.0015, 0.0019, 0.0464,  ..., 0.0772, 0.0025, 0.0672],\n",
            "        ...,\n",
            "        [0.0022, 0.0026, 0.0321,  ..., 0.1198, 0.0031, 0.0503],\n",
            "        [0.0030, 0.0022, 0.0394,  ..., 0.1310, 0.0035, 0.0516],\n",
            "        [0.0020, 0.0028, 0.1161,  ..., 0.0566, 0.0025, 0.0171]])\n",
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n",
            "                                      \n",
            "\u001b[A{'eval_loss': 0.15192168951034546, 'eval_hier_f1': 0.3995064013573963, 'eval_hier_precision': 0.7717520858164482, 'eval_hier_recall': 0.2695109261186264, 'eval_runtime': 5.6233, 'eval_samples_per_second': 177.832, 'eval_steps_per_second': 22.229, 'epoch': 1.0}\n",
            " 20% 938/4690 [04:11<15:19,  4.08it/s]\n",
            "100% 125/125 [00:05<00:00, 22.48it/s]\u001b[A\n",
            "{'loss': 0.1455, 'learning_rate': 3.0684434968017055e-05, 'epoch': 1.07}\n",
            "{'loss': 0.1327, 'learning_rate': 2.6526652452025587e-05, 'epoch': 1.6}\n",
            " 40% 1876/4690 [08:36<10:55,  4.29it/s]\n",
            "  0% 0/125 [00:00<?, ?it/s]\u001b[A\n",
            "  3% 4/125 [00:00<00:04, 27.19it/s]\u001b[A\n",
            "  6% 7/125 [00:00<00:04, 25.46it/s]\u001b[A\n",
            "  8% 10/125 [00:00<00:04, 25.55it/s]\u001b[A\n",
            " 10% 13/125 [00:00<00:04, 22.66it/s]\u001b[A\n",
            " 13% 16/125 [00:00<00:04, 23.27it/s]\u001b[A\n",
            " 15% 19/125 [00:00<00:04, 22.10it/s]\u001b[A\n",
            " 18% 23/125 [00:00<00:03, 26.15it/s]\u001b[A\n",
            " 21% 26/125 [00:01<00:03, 26.87it/s]\u001b[A\n",
            " 23% 29/125 [00:01<00:03, 26.09it/s]\u001b[A\n",
            " 26% 32/125 [00:01<00:03, 26.78it/s]\u001b[A\n",
            " 29% 36/125 [00:01<00:03, 28.36it/s]\u001b[A\n",
            " 31% 39/125 [00:01<00:03, 26.37it/s]\u001b[A\n",
            " 34% 42/125 [00:01<00:03, 25.00it/s]\u001b[A\n",
            " 37% 46/125 [00:01<00:02, 26.48it/s]\u001b[A\n",
            " 39% 49/125 [00:01<00:03, 24.83it/s]\u001b[A\n",
            " 42% 52/125 [00:02<00:03, 23.03it/s]\u001b[A\n",
            " 44% 55/125 [00:02<00:03, 22.75it/s]\u001b[A\n",
            " 46% 58/125 [00:02<00:03, 21.08it/s]\u001b[A\n",
            " 49% 61/125 [00:02<00:02, 21.45it/s]\u001b[A\n",
            " 51% 64/125 [00:02<00:02, 20.37it/s]\u001b[A\n",
            " 54% 67/125 [00:02<00:02, 19.66it/s]\u001b[A\n",
            " 56% 70/125 [00:02<00:02, 20.71it/s]\u001b[A\n",
            " 58% 73/125 [00:03<00:02, 19.75it/s]\u001b[A\n",
            " 61% 76/125 [00:03<00:02, 20.64it/s]\u001b[A\n",
            " 63% 79/125 [00:03<00:02, 20.26it/s]\u001b[A\n",
            " 66% 82/125 [00:03<00:02, 20.96it/s]\u001b[A\n",
            " 68% 85/125 [00:03<00:01, 21.57it/s]\u001b[A\n",
            " 70% 88/125 [00:03<00:01, 21.17it/s]\u001b[A\n",
            " 73% 91/125 [00:03<00:01, 20.63it/s]\u001b[A\n",
            " 75% 94/125 [00:04<00:01, 20.43it/s]\u001b[A\n",
            " 78% 97/125 [00:04<00:01, 21.95it/s]\u001b[A\n",
            " 80% 100/125 [00:04<00:01, 21.62it/s]\u001b[A\n",
            " 82% 103/125 [00:04<00:01, 21.51it/s]\u001b[A\n",
            " 85% 106/125 [00:04<00:00, 22.89it/s]\u001b[A\n",
            " 87% 109/125 [00:04<00:00, 21.63it/s]\u001b[A\n",
            " 90% 112/125 [00:04<00:00, 22.37it/s]\u001b[A\n",
            " 92% 115/125 [00:05<00:00, 23.05it/s]\u001b[A\n",
            " 94% 118/125 [00:05<00:00, 22.42it/s]\u001b[A\n",
            " 97% 121/125 [00:05<00:00, 23.81it/s]\u001b[A\n",
            " 99% 124/125 [00:05<00:00, 22.39it/s]\u001b[Atensor([[0.0011, 0.0012, 0.0119,  ..., 0.0561, 0.0012, 0.0073],\n",
            "        [0.0013, 0.0011, 0.0075,  ..., 0.0715, 0.0018, 0.0287],\n",
            "        [0.0003, 0.0004, 0.0134,  ..., 0.0202, 0.0006, 0.0455],\n",
            "        ...,\n",
            "        [0.0016, 0.0014, 0.0100,  ..., 0.1044, 0.0023, 0.0286],\n",
            "        [0.0012, 0.0013, 0.0113,  ..., 0.0744, 0.0018, 0.0303],\n",
            "        [0.0006, 0.0009, 0.0058,  ..., 0.0170, 0.0011, 0.0067]])\n",
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 0.1413423866033554, 'eval_hier_f1': 0.4391727493917275, 'eval_hier_precision': 0.8153585544889893, 'eval_hier_recall': 0.3005202913631634, 'eval_runtime': 5.5658, 'eval_samples_per_second': 179.668, 'eval_steps_per_second': 22.458, 'epoch': 2.0}\n",
            " 40% 1876/4690 [08:41<10:55,  4.29it/s]\n",
            "100% 125/125 [00:05<00:00, 22.39it/s]\u001b[A\n",
            "{'loss': 0.1231, 'learning_rate': 2.2368869936034115e-05, 'epoch': 2.13}\n",
            "{'loss': 0.1096, 'learning_rate': 1.8211087420042643e-05, 'epoch': 2.67}\n",
            " 60% 2814/4690 [13:06<07:24,  4.22it/s]\n",
            "  0% 0/125 [00:00<?, ?it/s]\u001b[A\n",
            "  3% 4/125 [00:00<00:04, 27.56it/s]\u001b[A\n",
            "  6% 7/125 [00:00<00:04, 25.81it/s]\u001b[A\n",
            "  8% 10/125 [00:00<00:04, 25.70it/s]\u001b[A\n",
            " 10% 13/125 [00:00<00:04, 22.95it/s]\u001b[A\n",
            " 13% 16/125 [00:00<00:04, 23.31it/s]\u001b[A\n",
            " 15% 19/125 [00:00<00:04, 22.21it/s]\u001b[A\n",
            " 18% 23/125 [00:00<00:03, 26.12it/s]\u001b[A\n",
            " 21% 26/125 [00:01<00:03, 26.55it/s]\u001b[A\n",
            " 23% 29/125 [00:01<00:03, 25.97it/s]\u001b[A\n",
            " 26% 32/125 [00:01<00:03, 26.68it/s]\u001b[A\n",
            " 29% 36/125 [00:01<00:03, 28.14it/s]\u001b[A\n",
            " 31% 39/125 [00:01<00:03, 26.11it/s]\u001b[A\n",
            " 34% 42/125 [00:01<00:03, 25.05it/s]\u001b[A\n",
            " 37% 46/125 [00:01<00:02, 26.37it/s]\u001b[A\n",
            " 39% 49/125 [00:01<00:03, 24.77it/s]\u001b[A\n",
            " 42% 52/125 [00:02<00:03, 22.81it/s]\u001b[A\n",
            " 44% 55/125 [00:02<00:03, 22.35it/s]\u001b[A\n",
            " 46% 58/125 [00:02<00:03, 20.75it/s]\u001b[A\n",
            " 49% 61/125 [00:02<00:03, 21.11it/s]\u001b[A\n",
            " 51% 64/125 [00:02<00:03, 20.13it/s]\u001b[A\n",
            " 54% 67/125 [00:02<00:02, 19.50it/s]\u001b[A\n",
            " 56% 70/125 [00:02<00:02, 20.63it/s]\u001b[A\n",
            " 58% 73/125 [00:03<00:02, 19.79it/s]\u001b[A\n",
            " 61% 76/125 [00:03<00:02, 20.57it/s]\u001b[A\n",
            " 63% 79/125 [00:03<00:02, 20.12it/s]\u001b[A\n",
            " 66% 82/125 [00:03<00:02, 20.54it/s]\u001b[A\n",
            " 68% 85/125 [00:03<00:01, 21.24it/s]\u001b[A\n",
            " 70% 88/125 [00:03<00:01, 20.81it/s]\u001b[A\n",
            " 73% 91/125 [00:04<00:01, 20.36it/s]\u001b[A\n",
            " 75% 94/125 [00:04<00:01, 20.34it/s]\u001b[A\n",
            " 78% 97/125 [00:04<00:01, 22.11it/s]\u001b[A\n",
            " 80% 100/125 [00:04<00:01, 21.71it/s]\u001b[A\n",
            " 82% 103/125 [00:04<00:01, 21.44it/s]\u001b[A\n",
            " 85% 106/125 [00:04<00:00, 22.73it/s]\u001b[A\n",
            " 87% 109/125 [00:04<00:00, 21.38it/s]\u001b[A\n",
            " 90% 112/125 [00:04<00:00, 22.15it/s]\u001b[A\n",
            " 92% 115/125 [00:05<00:00, 22.83it/s]\u001b[A\n",
            " 94% 118/125 [00:05<00:00, 22.39it/s]\u001b[A\n",
            " 97% 121/125 [00:05<00:00, 23.85it/s]\u001b[A\n",
            " 99% 124/125 [00:05<00:00, 22.41it/s]\u001b[Atensor([[0.0026, 0.0026, 0.0275,  ..., 0.1115, 0.0019, 0.0141],\n",
            "        [0.0017, 0.0011, 0.0043,  ..., 0.1319, 0.0020, 0.0262],\n",
            "        [0.0003, 0.0004, 0.0089,  ..., 0.0166, 0.0005, 0.0985],\n",
            "        ...,\n",
            "        [0.0010, 0.0007, 0.0200,  ..., 0.0930, 0.0013, 0.0168],\n",
            "        [0.0014, 0.0014, 0.0052,  ..., 0.0610, 0.0019, 0.0253],\n",
            "        [0.0006, 0.0010, 0.0045,  ..., 0.0101, 0.0011, 0.0043]])\n",
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 0.13878045976161957, 'eval_hier_f1': 0.5296301388697923, 'eval_hier_precision': 0.7803889789303079, 'eval_hier_recall': 0.4008324661810614, 'eval_runtime': 5.5908, 'eval_samples_per_second': 178.865, 'eval_steps_per_second': 22.358, 'epoch': 3.0}\n",
            " 60% 2814/4690 [13:11<07:24,  4.22it/s]\n",
            "100% 125/125 [00:05<00:00, 22.41it/s]\u001b[A\n",
            "{'loss': 0.1011, 'learning_rate': 1.4053304904051172e-05, 'epoch': 3.2}\n",
            "{'loss': 0.092, 'learning_rate': 9.895522388059702e-06, 'epoch': 3.73}\n",
            " 80% 3752/4690 [17:37<03:42,  4.21it/s]\n",
            "  0% 0/125 [00:00<?, ?it/s]\u001b[A\n",
            "  3% 4/125 [00:00<00:04, 27.55it/s]\u001b[A\n",
            "  6% 7/125 [00:00<00:04, 25.69it/s]\u001b[A\n",
            "  8% 10/125 [00:00<00:04, 25.53it/s]\u001b[A\n",
            " 10% 13/125 [00:00<00:04, 22.72it/s]\u001b[A\n",
            " 13% 16/125 [00:00<00:04, 23.23it/s]\u001b[A\n",
            " 15% 19/125 [00:00<00:04, 22.23it/s]\u001b[A\n",
            " 18% 23/125 [00:00<00:03, 26.23it/s]\u001b[A\n",
            " 21% 26/125 [00:01<00:03, 26.86it/s]\u001b[A\n",
            " 23% 29/125 [00:01<00:03, 26.08it/s]\u001b[A\n",
            " 26% 32/125 [00:01<00:03, 26.75it/s]\u001b[A\n",
            " 29% 36/125 [00:01<00:03, 28.29it/s]\u001b[A\n",
            " 31% 39/125 [00:01<00:03, 26.35it/s]\u001b[A\n",
            " 34% 42/125 [00:01<00:03, 25.08it/s]\u001b[A\n",
            " 37% 46/125 [00:01<00:02, 26.50it/s]\u001b[A\n",
            " 39% 49/125 [00:01<00:03, 24.82it/s]\u001b[A\n",
            " 42% 52/125 [00:02<00:03, 23.06it/s]\u001b[A\n",
            " 44% 55/125 [00:02<00:03, 22.68it/s]\u001b[A\n",
            " 46% 58/125 [00:02<00:03, 21.02it/s]\u001b[A\n",
            " 49% 61/125 [00:02<00:03, 21.27it/s]\u001b[A\n",
            " 51% 64/125 [00:02<00:03, 20.25it/s]\u001b[A\n",
            " 54% 67/125 [00:02<00:02, 19.66it/s]\u001b[A\n",
            " 56% 70/125 [00:02<00:02, 20.70it/s]\u001b[A\n",
            " 58% 73/125 [00:03<00:02, 19.80it/s]\u001b[A\n",
            " 61% 76/125 [00:03<00:02, 20.48it/s]\u001b[A\n",
            " 63% 79/125 [00:03<00:02, 19.96it/s]\u001b[A\n",
            " 66% 82/125 [00:03<00:02, 20.31it/s]\u001b[A\n",
            " 68% 85/125 [00:03<00:01, 20.97it/s]\u001b[A\n",
            " 70% 88/125 [00:03<00:01, 20.66it/s]\u001b[A\n",
            " 73% 91/125 [00:04<00:01, 20.13it/s]\u001b[A\n",
            " 75% 94/125 [00:04<00:01, 19.94it/s]\u001b[A\n",
            " 78% 97/125 [00:04<00:01, 21.66it/s]\u001b[A\n",
            " 80% 100/125 [00:04<00:01, 21.15it/s]\u001b[A\n",
            " 82% 103/125 [00:04<00:01, 21.04it/s]\u001b[A\n",
            " 85% 106/125 [00:04<00:00, 22.41it/s]\u001b[A\n",
            " 87% 109/125 [00:04<00:00, 21.17it/s]\u001b[A\n",
            " 90% 112/125 [00:04<00:00, 22.03it/s]\u001b[A\n",
            " 92% 115/125 [00:05<00:00, 22.57it/s]\u001b[A\n",
            " 94% 118/125 [00:05<00:00, 22.03it/s]\u001b[A\n",
            " 97% 121/125 [00:05<00:00, 23.51it/s]\u001b[A\n",
            " 99% 124/125 [00:05<00:00, 22.23it/s]\u001b[Atensor([[0.0015, 0.0017, 0.0396,  ..., 0.1139, 0.0012, 0.0076],\n",
            "        [0.0016, 0.0008, 0.0047,  ..., 0.1277, 0.0021, 0.0280],\n",
            "        [0.0003, 0.0004, 0.0060,  ..., 0.0167, 0.0006, 0.1263],\n",
            "        ...,\n",
            "        [0.0005, 0.0003, 0.0145,  ..., 0.0646, 0.0007, 0.0182],\n",
            "        [0.0009, 0.0007, 0.0046,  ..., 0.0312, 0.0013, 0.0239],\n",
            "        [0.0006, 0.0010, 0.0039,  ..., 0.0069, 0.0011, 0.0048]])\n",
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 0.13906295597553253, 'eval_hier_f1': 0.567488187970885, 'eval_hier_precision': 0.7343027098479842, 'eval_hier_recall': 0.46243496357960456, 'eval_runtime': 5.6345, 'eval_samples_per_second': 177.479, 'eval_steps_per_second': 22.185, 'epoch': 4.0}\n",
            " 80% 3752/4690 [17:42<03:42,  4.21it/s]\n",
            "100% 125/125 [00:05<00:00, 22.23it/s]\u001b[A\n",
            "{'loss': 0.0835, 'learning_rate': 5.73773987206823e-06, 'epoch': 4.26}\n",
            "{'loss': 0.0773, 'learning_rate': 1.579957356076759e-06, 'epoch': 4.8}\n",
            "100% 4690/4690 [22:05<00:00,  4.21it/s]\n",
            "  0% 0/125 [00:00<?, ?it/s]\u001b[A\n",
            "  3% 4/125 [00:00<00:04, 27.48it/s]\u001b[A\n",
            "  6% 7/125 [00:00<00:04, 25.40it/s]\u001b[A\n",
            "  8% 10/125 [00:00<00:04, 25.21it/s]\u001b[A\n",
            " 10% 13/125 [00:00<00:04, 22.53it/s]\u001b[A\n",
            " 13% 16/125 [00:00<00:04, 23.10it/s]\u001b[A\n",
            " 15% 19/125 [00:00<00:04, 22.08it/s]\u001b[A\n",
            " 18% 23/125 [00:00<00:03, 26.09it/s]\u001b[A\n",
            " 21% 26/125 [00:01<00:03, 26.60it/s]\u001b[A\n",
            " 23% 29/125 [00:01<00:03, 25.69it/s]\u001b[A\n",
            " 26% 32/125 [00:01<00:03, 26.55it/s]\u001b[A\n",
            " 29% 36/125 [00:01<00:03, 28.05it/s]\u001b[A\n",
            " 31% 39/125 [00:01<00:03, 26.12it/s]\u001b[A\n",
            " 34% 42/125 [00:01<00:03, 25.09it/s]\u001b[A\n",
            " 37% 46/125 [00:01<00:03, 26.32it/s]\u001b[A\n",
            " 39% 49/125 [00:01<00:03, 24.74it/s]\u001b[A\n",
            " 42% 52/125 [00:02<00:03, 22.96it/s]\u001b[A\n",
            " 44% 55/125 [00:02<00:03, 22.63it/s]\u001b[A\n",
            " 46% 58/125 [00:02<00:03, 20.93it/s]\u001b[A\n",
            " 49% 61/125 [00:02<00:02, 21.47it/s]\u001b[A\n",
            " 51% 64/125 [00:02<00:02, 20.34it/s]\u001b[A\n",
            " 54% 67/125 [00:02<00:02, 19.62it/s]\u001b[A\n",
            " 56% 70/125 [00:02<00:02, 20.84it/s]\u001b[A\n",
            " 58% 73/125 [00:03<00:02, 19.89it/s]\u001b[A\n",
            " 61% 76/125 [00:03<00:02, 20.52it/s]\u001b[A\n",
            " 63% 79/125 [00:03<00:02, 20.06it/s]\u001b[A\n",
            " 66% 82/125 [00:03<00:02, 20.30it/s]\u001b[A\n",
            " 68% 85/125 [00:03<00:01, 21.11it/s]\u001b[A\n",
            " 70% 88/125 [00:03<00:01, 20.70it/s]\u001b[A\n",
            " 73% 91/125 [00:04<00:01, 20.15it/s]\u001b[A\n",
            " 75% 94/125 [00:04<00:01, 20.01it/s]\u001b[A\n",
            " 78% 97/125 [00:04<00:01, 21.53it/s]\u001b[A\n",
            " 80% 100/125 [00:04<00:01, 21.04it/s]\u001b[A\n",
            " 82% 103/125 [00:04<00:01, 20.82it/s]\u001b[A\n",
            " 85% 106/125 [00:04<00:00, 22.11it/s]\u001b[A\n",
            " 87% 109/125 [00:04<00:00, 20.88it/s]\u001b[A\n",
            " 90% 112/125 [00:05<00:00, 21.65it/s]\u001b[A\n",
            " 92% 115/125 [00:05<00:00, 22.12it/s]\u001b[A\n",
            " 94% 118/125 [00:05<00:00, 21.87it/s]\u001b[A\n",
            " 97% 121/125 [00:05<00:00, 23.17it/s]\u001b[A\n",
            " 99% 124/125 [00:05<00:00, 21.76it/s]\u001b[Atensor([[0.0011, 0.0012, 0.0254,  ..., 0.1550, 0.0010, 0.0089],\n",
            "        [0.0017, 0.0008, 0.0061,  ..., 0.1499, 0.0022, 0.0336],\n",
            "        [0.0003, 0.0003, 0.0051,  ..., 0.0163, 0.0005, 0.1254],\n",
            "        ...,\n",
            "        [0.0004, 0.0003, 0.0189,  ..., 0.0494, 0.0006, 0.0153],\n",
            "        [0.0005, 0.0004, 0.0050,  ..., 0.0231, 0.0007, 0.0170],\n",
            "        [0.0005, 0.0007, 0.0034,  ..., 0.0064, 0.0009, 0.0039]])\n",
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 0.14084386825561523, 'eval_hier_f1': 0.5724888035828535, 'eval_hier_precision': 0.7431893687707641, 'eval_hier_recall': 0.4655567117585848, 'eval_runtime': 5.6664, 'eval_samples_per_second': 176.478, 'eval_steps_per_second': 22.06, 'epoch': 5.0}\n",
            "100% 4690/4690 [22:11<00:00,  4.21it/s]\n",
            "100% 125/125 [00:05<00:00, 21.76it/s]\u001b[A\n",
            "{'train_runtime': 1351.5643, 'train_samples_per_second': 27.746, 'train_steps_per_second': 3.47, 'train_loss': 0.11490457469720576, 'epoch': 5.0}\n",
            "100% 4690/4690 [22:31<00:00,  3.47it/s]\n",
            " 98% 123/125 [00:05<00:00, 23.45it/s]tensor([[0.0011, 0.0012, 0.0254,  ..., 0.1550, 0.0010, 0.0089],\n",
            "        [0.0017, 0.0008, 0.0061,  ..., 0.1499, 0.0022, 0.0336],\n",
            "        [0.0003, 0.0003, 0.0051,  ..., 0.0163, 0.0005, 0.1254],\n",
            "        ...,\n",
            "        [0.0004, 0.0003, 0.0189,  ..., 0.0494, 0.0006, 0.0153],\n",
            "        [0.0005, 0.0004, 0.0050,  ..., 0.0231, 0.0007, 0.0170],\n",
            "        [0.0005, 0.0007, 0.0034,  ..., 0.0064, 0.0009, 0.0039]])\n",
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n",
            "100% 125/125 [00:05<00:00, 22.50it/s]\n",
            "(dev_set) Evaluation results: {\n",
            "    \"eval_loss\": 0.14084386825561523,\n",
            "    \"eval_hier_f1\": 0.5724888035828535,\n",
            "    \"eval_hier_precision\": 0.7431893687707641,\n",
            "    \"eval_hier_recall\": 0.4655567117585848,\n",
            "    \"eval_runtime\": 5.5988,\n",
            "    \"eval_samples_per_second\": 178.611,\n",
            "    \"eval_steps_per_second\": 22.326,\n",
            "    \"epoch\": 5.0\n",
            "}\n",
            "Saving fine-tuned model to /gdrive/My Drive/projects/bambas/fine_tuning_with_class/jhu-clsp-bernice-semeval2024-test-unlabeled-classifier\n",
            "Prediction on test_set\n",
            "#0:  68% 32/47 [00:00<00:00, 112.58ba/s]\n",
            "#0: 100% 47/47 [00:00<00:00, 117.68ba/s]\n",
            "\n",
            "#1:  21% 10/47 [00:00<00:00, 91.76ba/s]\u001b[A\n",
            "#1:  53% 25/47 [00:00<00:00, 121.01ba/s]\u001b[A\n",
            "#1: 100% 47/47 [00:00<00:00, 146.53ba/s]\n",
            "\n",
            "\n",
            "\n",
            "#3:   0% 0/47 [00:00<?, ?ba/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "#2:   0% 0/47 [00:00<?, ?ba/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "#3:  21% 10/47 [00:00<00:00, 91.13ba/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "#2:  19% 9/47 [00:00<00:00, 88.55ba/s]\u001b[A\u001b[A\n",
            "\n",
            "#2:  49% 23/47 [00:00<00:00, 118.08ba/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "#3:  53% 25/47 [00:00<00:00, 115.94ba/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "#2:  81% 38/47 [00:00<00:00, 131.36ba/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "#3: 100% 47/47 [00:00<00:00, 139.36ba/s]\n",
            "#2: 100% 47/47 [00:00<00:00, 128.02ba/s]\n",
            "Batch no. 1. Transferring to device\n",
            "Batch no. 2. Transferring to device\n",
            "Batch no. 3. Transferring to device\n",
            "Batch no. 4. Transferring to device\n",
            "Batch no. 5. Transferring to device\n",
            "Batch no. 6. Transferring to device\n",
            "Batch no. 7. Transferring to device\n",
            "Batch no. 8. Transferring to device\n",
            "Batch no. 9. Transferring to device\n",
            "Batch no. 10. Transferring to device\n",
            "Batch no. 11. Transferring to device\n",
            "Batch no. 12. Transferring to device\n",
            "Batch no. 13. Transferring to device\n",
            "Batch no. 14. Transferring to device\n",
            "Batch no. 15. Transferring to device\n",
            "Batch no. 16. Transferring to device\n",
            "Batch no. 17. Transferring to device\n",
            "Batch no. 18. Transferring to device\n",
            "Batch no. 19. Transferring to device\n",
            "Batch no. 20. Transferring to device\n",
            "Batch no. 21. Transferring to device\n",
            "Batch no. 22. Transferring to device\n",
            "Batch no. 23. Transferring to device\n",
            "Batch no. 24. Transferring to device\n",
            "Batch no. 25. Transferring to device\n",
            "Batch no. 26. Transferring to device\n",
            "Batch no. 27. Transferring to device\n",
            "Batch no. 28. Transferring to device\n",
            "Batch no. 29. Transferring to device\n",
            "Batch no. 30. Transferring to device\n",
            "Batch no. 31. Transferring to device\n",
            "Batch no. 32. Transferring to device\n",
            "Batch no. 33. Transferring to device\n",
            "Batch no. 34. Transferring to device\n",
            "Batch no. 35. Transferring to device\n",
            "Batch no. 36. Transferring to device\n",
            "Batch no. 37. Transferring to device\n",
            "Batch no. 38. Transferring to device\n",
            "Batch no. 39. Transferring to device\n",
            "Batch no. 40. Transferring to device\n",
            "Batch no. 41. Transferring to device\n",
            "Batch no. 42. Transferring to device\n",
            "Batch no. 43. Transferring to device\n",
            "Batch no. 44. Transferring to device\n",
            "Batch no. 45. Transferring to device\n",
            "Batch no. 46. Transferring to device\n",
            "Batch no. 47. Transferring to device\n",
            "Batch no. 48. Transferring to device\n",
            "Batch no. 49. Transferring to device\n",
            "Batch no. 50. Transferring to device\n",
            "Batch no. 51. Transferring to device\n",
            "Batch no. 52. Transferring to device\n",
            "Batch no. 53. Transferring to device\n",
            "Batch no. 54. Transferring to device\n",
            "Batch no. 55. Transferring to device\n",
            "Batch no. 56. Transferring to device\n",
            "Batch no. 57. Transferring to device\n",
            "Batch no. 58. Transferring to device\n",
            "Batch no. 59. Transferring to device\n",
            "Batch no. 60. Transferring to device\n",
            "Batch no. 61. Transferring to device\n",
            "Batch no. 62. Transferring to device\n",
            "Batch no. 63. Transferring to device\n",
            "Batch no. 64. Transferring to device\n",
            "Batch no. 65. Transferring to device\n",
            "Batch no. 66. Transferring to device\n",
            "Batch no. 67. Transferring to device\n",
            "Batch no. 68. Transferring to device\n",
            "Batch no. 69. Transferring to device\n",
            "Batch no. 70. Transferring to device\n",
            "Batch no. 71. Transferring to device\n",
            "Batch no. 72. Transferring to device\n",
            "Batch no. 73. Transferring to device\n",
            "Batch no. 74. Transferring to device\n",
            "Batch no. 75. Transferring to device\n",
            "Batch no. 76. Transferring to device\n",
            "Batch no. 77. Transferring to device\n",
            "Batch no. 78. Transferring to device\n",
            "Batch no. 79. Transferring to device\n",
            "Batch no. 80. Transferring to device\n",
            "Batch no. 81. Transferring to device\n",
            "Batch no. 82. Transferring to device\n",
            "Batch no. 83. Transferring to device\n",
            "Batch no. 84. Transferring to device\n",
            "Batch no. 85. Transferring to device\n",
            "Batch no. 86. Transferring to device\n",
            "Batch no. 87. Transferring to device\n",
            "Batch no. 88. Transferring to device\n",
            "Batch no. 89. Transferring to device\n",
            "Batch no. 90. Transferring to device\n",
            "Batch no. 91. Transferring to device\n",
            "Batch no. 92. Transferring to device\n",
            "Batch no. 93. Transferring to device\n",
            "Batch no. 94. Transferring to device\n",
            "Batch no. 95. Transferring to device\n",
            "Batch no. 96. Transferring to device\n",
            "Batch no. 97. Transferring to device\n",
            "Batch no. 98. Transferring to device\n",
            "Batch no. 99. Transferring to device\n",
            "Batch no. 100. Transferring to device\n",
            "Batch no. 101. Transferring to device\n",
            "Batch no. 102. Transferring to device\n",
            "Batch no. 103. Transferring to device\n",
            "Batch no. 104. Transferring to device\n",
            "Batch no. 105. Transferring to device\n",
            "Batch no. 106. Transferring to device\n",
            "Batch no. 107. Transferring to device\n",
            "Batch no. 108. Transferring to device\n",
            "Batch no. 109. Transferring to device\n",
            "Batch no. 110. Transferring to device\n",
            "Batch no. 111. Transferring to device\n",
            "Batch no. 112. Transferring to device\n",
            "Batch no. 113. Transferring to device\n",
            "Batch no. 114. Transferring to device\n",
            "Batch no. 115. Transferring to device\n",
            "Batch no. 116. Transferring to device\n",
            "Batch no. 117. Transferring to device\n",
            "Batch no. 118. Transferring to device\n",
            "Batch no. 119. Transferring to device\n",
            "Batch no. 120. Transferring to device\n",
            "Batch no. 121. Transferring to device\n",
            "Batch no. 122. Transferring to device\n",
            "Batch no. 123. Transferring to device\n",
            "Batch no. 124. Transferring to device\n",
            "Batch no. 125. Transferring to device\n",
            "Batch no. 126. Transferring to device\n",
            "Batch no. 127. Transferring to device\n",
            "Batch no. 128. Transferring to device\n",
            "Batch no. 129. Transferring to device\n",
            "Batch no. 130. Transferring to device\n",
            "Batch no. 131. Transferring to device\n",
            "Batch no. 132. Transferring to device\n",
            "Batch no. 133. Transferring to device\n",
            "Batch no. 134. Transferring to device\n",
            "Batch no. 135. Transferring to device\n",
            "Batch no. 136. Transferring to device\n",
            "Batch no. 137. Transferring to device\n",
            "Batch no. 138. Transferring to device\n",
            "Batch no. 139. Transferring to device\n",
            "Batch no. 140. Transferring to device\n",
            "Batch no. 141. Transferring to device\n",
            "Batch no. 142. Transferring to device\n",
            "Batch no. 143. Transferring to device\n",
            "Batch no. 144. Transferring to device\n",
            "Batch no. 145. Transferring to device\n",
            "Batch no. 146. Transferring to device\n",
            "Batch no. 147. Transferring to device\n",
            "Batch no. 148. Transferring to device\n",
            "Batch no. 149. Transferring to device\n",
            "Batch no. 150. Transferring to device\n",
            "Batch no. 151. Transferring to device\n",
            "Batch no. 152. Transferring to device\n",
            "Batch no. 153. Transferring to device\n",
            "Batch no. 154. Transferring to device\n",
            "Batch no. 155. Transferring to device\n",
            "Batch no. 156. Transferring to device\n",
            "Batch no. 157. Transferring to device\n",
            "Batch no. 158. Transferring to device\n",
            "Batch no. 159. Transferring to device\n",
            "Batch no. 160. Transferring to device\n",
            "Batch no. 161. Transferring to device\n",
            "Batch no. 162. Transferring to device\n",
            "Batch no. 163. Transferring to device\n",
            "Batch no. 164. Transferring to device\n",
            "Batch no. 165. Transferring to device\n",
            "Batch no. 166. Transferring to device\n",
            "Batch no. 167. Transferring to device\n",
            "Batch no. 168. Transferring to device\n",
            "Batch no. 169. Transferring to device\n",
            "Batch no. 170. Transferring to device\n",
            "Batch no. 171. Transferring to device\n",
            "Batch no. 172. Transferring to device\n",
            "Batch no. 173. Transferring to device\n",
            "Batch no. 174. Transferring to device\n",
            "Batch no. 175. Transferring to device\n",
            "Batch no. 176. Transferring to device\n",
            "Batch no. 177. Transferring to device\n",
            "Batch no. 178. Transferring to device\n",
            "Batch no. 179. Transferring to device\n",
            "Batch no. 180. Transferring to device\n",
            "Batch no. 181. Transferring to device\n",
            "Batch no. 182. Transferring to device\n",
            "Batch no. 183. Transferring to device\n",
            "Batch no. 184. Transferring to device\n",
            "Batch no. 185. Transferring to device\n",
            "Batch no. 186. Transferring to device\n",
            "Batch no. 187. Transferring to device\n",
            "Batch no. 188. Transferring to device\n",
            "Predicting for task test set. No evaluation can be made locally. Saved predictions file to /gdrive/My Drive/projects/bambas/classification/1707956219_dev_labeled_predictions.json.txt\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature-extraction with BERNICE for external classification"
      ],
      "metadata": {
        "id": "JOW1xKlg_xKZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!PYTHONPATH=\"/gdrive/My Drive/projects/bambas\" python -m src.feature_extraction \\\n",
        "  --model jhu-clsp/bernice \\\n",
        "  --dataset semeval2024_test_unlabeled \\\n",
        "  --extraction_method cls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SGJLPC0I_xdm",
        "outputId": "e36451e3-6feb-4f64-95ea-f42d3abcf8d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-02-15 23:10:35.898796: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-02-15 23:10:35.898854: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-02-15 23:10:35.900253: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-02-15 23:10:36.915817: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Running on Google Colab, workdir: /gdrive/My Drive/projects/bambas\n",
            "Running on Google Colab, workdir: /gdrive/My Drive/projects/bambas\n",
            "Arguments: Namespace(output_dir='', dataset='semeval2024_test_unlabeled', model='jhu-clsp/bernice', extraction_method='cls', layers=[], agg_method=None)\n",
            "Dataset Lengths 7500 1000 1500\n",
            "Using device: {'': 0}\n",
            "#0:   7% 2/30 [00:00<00:01, 16.25ba/s]\n",
            "#0:  17% 5/30 [00:00<00:01, 20.49ba/s]\n",
            "#0:  27% 8/30 [00:00<00:01, 21.49ba/s]\n",
            "#0:  37% 11/30 [00:00<00:00, 23.85ba/s]\n",
            "#1:  27% 8/30 [00:00<00:00, 24.54ba/s]\u001b[A\n",
            "\n",
            "#0:  47% 14/30 [00:00<00:00, 23.16ba/s]\n",
            "#1:  37% 11/30 [00:00<00:00, 22.89ba/s]\u001b[A\n",
            "\n",
            "#0:  57% 17/30 [00:00<00:00, 24.47ba/s]\n",
            "\n",
            "\n",
            "#3:   0% 0/30 [00:00<?, ?ba/s]\u001b[A\u001b[A\u001b[A\n",
            "#1:  47% 14/30 [00:00<00:00, 23.61ba/s]\u001b[A\n",
            "\n",
            "#0:  67% 20/30 [00:00<00:00, 24.80ba/s]\n",
            "\n",
            "\n",
            "#3:   7% 2/30 [00:00<00:01, 16.66ba/s]\u001b[A\u001b[A\u001b[A\n",
            "#1:  57% 17/30 [00:00<00:00, 24.53ba/s]\u001b[A\n",
            "\n",
            "#0:  80% 24/30 [00:00<00:00, 27.00ba/s]\n",
            "#1:  67% 20/30 [00:00<00:00, 25.99ba/s]\u001b[A\n",
            "\n",
            "\n",
            "#3:  17% 5/30 [00:00<00:01, 21.79ba/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "#0:  90% 27/30 [00:01<00:00, 26.94ba/s]\n",
            "#1:  77% 23/30 [00:00<00:00, 26.56ba/s]\u001b[A\n",
            "\n",
            "\n",
            "#3:  27% 8/30 [00:00<00:00, 23.40ba/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "#0: 100% 30/30 [00:01<00:00, 25.46ba/s]\n",
            "\n",
            "#1:  87% 26/30 [00:01<00:00, 26.35ba/s]\u001b[A\n",
            "\n",
            "\n",
            "#3:  37% 11/30 [00:00<00:00, 24.59ba/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "#2:  57% 17/30 [00:00<00:00, 27.21ba/s]\u001b[A\u001b[A\n",
            "#1: 100% 30/30 [00:01<00:00, 25.62ba/s]\n",
            "\n",
            "\n",
            "#2:  67% 20/30 [00:00<00:00, 27.34ba/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "#3:  50% 15/30 [00:00<00:00, 26.40ba/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "#2:  77% 23/30 [00:00<00:00, 27.24ba/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "#3:  60% 18/30 [00:00<00:00, 27.40ba/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "#2: 100% 30/30 [00:00<00:00, 30.22ba/s]\n",
            "\n",
            "\n",
            "\n",
            "#3:  70% 21/30 [00:00<00:00, 24.10ba/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "#3:  80% 24/30 [00:00<00:00, 24.78ba/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "#3: 100% 30/30 [00:01<00:00, 25.55ba/s]\n",
            "#0: 100% 4/4 [00:00<00:00, 21.21ba/s]\n",
            "\n",
            "#1:   0% 0/4 [00:00<?, ?ba/s]\u001b[A\n",
            "\n",
            "#2:   0% 0/4 [00:00<?, ?ba/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "#3:   0% 0/4 [00:00<?, ?ba/s]\u001b[A\u001b[A\u001b[A\n",
            "#1:  50% 2/4 [00:00<00:00, 13.66ba/s]\u001b[A\n",
            "\n",
            "#1: 100% 4/4 [00:00<00:00, 17.65ba/s]\n",
            "\n",
            "\n",
            "\n",
            "#2: 100% 4/4 [00:00<00:00, 19.70ba/s]\n",
            "#3: 100% 4/4 [00:00<00:00, 20.98ba/s]\n",
            "#0:  50% 3/6 [00:00<00:00, 11.90ba/s]\n",
            "#0: 100% 6/6 [00:00<00:00, 15.45ba/s]\n",
            "\n",
            "#1:  33% 2/6 [00:00<00:00, 18.85ba/s]\u001b[A\n",
            "\n",
            "#2:   0% 0/6 [00:00<?, ?ba/s]\u001b[A\u001b[A\n",
            "#1: 100% 6/6 [00:00<00:00, 22.86ba/s]\n",
            "\n",
            "\n",
            "\n",
            "#3:   0% 0/6 [00:00<?, ?ba/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "#2: 100% 6/6 [00:00<00:00, 29.18ba/s]\n",
            "\n",
            "\n",
            "\n",
            "#3:  33% 2/6 [00:00<00:00, 11.72ba/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "#3: 100% 6/6 [00:00<00:00, 18.80ba/s]\n",
            "You're using a XLMRobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "Asking to pad to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no padding.\n",
            "Batch no. 1\n",
            "Batch no. 2\n",
            "Batch no. 3\n",
            "Batch no. 4\n",
            "Batch no. 5\n",
            "Batch no. 6\n",
            "Batch no. 7\n",
            "Batch no. 8\n",
            "Batch no. 9\n",
            "Batch no. 10\n",
            "Batch no. 11\n",
            "Batch no. 12\n",
            "Batch no. 13\n",
            "Batch no. 14\n",
            "Batch no. 15\n",
            "Batch no. 16\n",
            "Batch no. 17\n",
            "Batch no. 18\n",
            "Batch no. 19\n",
            "Batch no. 20\n",
            "Batch no. 21\n",
            "Batch no. 22\n",
            "Batch no. 23\n",
            "Batch no. 24\n",
            "Batch no. 25\n",
            "Batch no. 26\n",
            "Batch no. 27\n",
            "Batch no. 28\n",
            "Batch no. 29\n",
            "Batch no. 30\n",
            "Batch no. 31\n",
            "Batch no. 32\n",
            "Batch no. 33\n",
            "Batch no. 34\n",
            "Batch no. 35\n",
            "Batch no. 36\n",
            "Batch no. 37\n",
            "Batch no. 38\n",
            "Batch no. 39\n",
            "Batch no. 40\n",
            "Batch no. 41\n",
            "Batch no. 42\n",
            "Batch no. 43\n",
            "Batch no. 44\n",
            "Batch no. 45\n",
            "Batch no. 46\n",
            "Batch no. 47\n",
            "Batch no. 48\n",
            "Batch no. 49\n",
            "Batch no. 50\n",
            "Batch no. 51\n",
            "Batch no. 52\n",
            "Batch no. 53\n",
            "Batch no. 54\n",
            "Batch no. 55\n",
            "Batch no. 56\n",
            "Batch no. 57\n",
            "Batch no. 58\n",
            "Batch no. 59\n",
            "Batch no. 60\n",
            "Batch no. 61\n",
            "Batch no. 62\n",
            "Batch no. 63\n",
            "Batch no. 64\n",
            "Batch no. 65\n",
            "Batch no. 66\n",
            "Batch no. 67\n",
            "Batch no. 68\n",
            "Batch no. 69\n",
            "Batch no. 70\n",
            "Batch no. 71\n",
            "Batch no. 72\n",
            "Batch no. 73\n",
            "Batch no. 74\n",
            "Batch no. 75\n",
            "Batch no. 76\n",
            "Batch no. 77\n",
            "Batch no. 78\n",
            "Batch no. 79\n",
            "Batch no. 80\n",
            "Batch no. 81\n",
            "Batch no. 82\n",
            "Batch no. 83\n",
            "Batch no. 84\n",
            "Batch no. 85\n",
            "Batch no. 86\n",
            "Batch no. 87\n",
            "Batch no. 88\n",
            "Batch no. 89\n",
            "Batch no. 90\n",
            "Batch no. 91\n",
            "Batch no. 92\n",
            "Batch no. 93\n",
            "Batch no. 94\n",
            "Batch no. 95\n",
            "Batch no. 96\n",
            "Batch no. 97\n",
            "Batch no. 98\n",
            "Batch no. 99\n",
            "Batch no. 100\n",
            "Batch no. 101\n",
            "Batch no. 102\n",
            "Batch no. 103\n",
            "Batch no. 104\n",
            "Batch no. 105\n",
            "Batch no. 106\n",
            "Batch no. 107\n",
            "Batch no. 108\n",
            "Batch no. 109\n",
            "Batch no. 110\n",
            "Batch no. 111\n",
            "Batch no. 112\n",
            "Batch no. 113\n",
            "Batch no. 114\n",
            "Batch no. 115\n",
            "Batch no. 116\n",
            "Batch no. 117\n",
            "Batch no. 118\n",
            "Batch no. 1\n",
            "Batch no. 2\n",
            "Batch no. 3\n",
            "Batch no. 4\n",
            "Batch no. 5\n",
            "Batch no. 6\n",
            "Batch no. 7\n",
            "Batch no. 8\n",
            "Batch no. 9\n",
            "Batch no. 10\n",
            "Batch no. 11\n",
            "Batch no. 12\n",
            "Batch no. 13\n",
            "Batch no. 14\n",
            "Batch no. 15\n",
            "Batch no. 16\n",
            "Batch no. 17\n",
            "Batch no. 18\n",
            "Batch no. 19\n",
            "Batch no. 20\n",
            "Batch no. 21\n",
            "Batch no. 22\n",
            "Batch no. 23\n",
            "Batch no. 24\n",
            "Batch no. 1\n",
            "Batch no. 2\n",
            "Batch no. 3\n",
            "Batch no. 4\n",
            "Batch no. 5\n",
            "Batch no. 6\n",
            "Batch no. 7\n",
            "Batch no. 8\n",
            "Batch no. 9\n",
            "Batch no. 10\n",
            "Batch no. 11\n",
            "Batch no. 12\n",
            "Batch no. 13\n",
            "Batch no. 14\n",
            "Batch no. 15\n",
            "Batch no. 16\n",
            "train_ft_path: /gdrive/My Drive/projects/bambas/feature_extraction//1708038715_jhu-clsp-bernice_train_features.json\n",
            "Saved feature-extraction file to /gdrive/My Drive/projects/bambas/feature_extraction//1708038715_jhu-clsp-bernice_train_features.json\n",
            "Saved feature-extraction file to /gdrive/My Drive/projects/bambas/feature_extraction//1708038715_jhu-clsp-bernice_test_features.json\n",
            "Saved feature-extraction file to /gdrive/My Drive/projects/bambas/feature_extraction//1708038715_jhu-clsp-bernice_dev_features.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!PYTHONPATH=\"/gdrive/My Drive/projects/bambas\" python -m src.classification \\\n",
        "  --classifier \"MLP\" \\\n",
        "  --dataset semeval2024_test_unlabeled \\\n",
        "  --train_features \"/gdrive/My Drive/projects/bambas/feature_extraction/1708038514_jhu-clsp-bernice_train_features.json\" \\\n",
        "  --test_features \"/gdrive/My Drive/projects/bambas/feature_extraction/1708038514_jhu-clsp-bernice_test_features.json\" \\\n",
        "  --dev_features \"/gdrive/My Drive/projects/bambas/feature_extraction/1708038514_jhu-clsp-bernice_dev_features.json\" \\\n",
        "  --seed 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hfMhywHFB7l_",
        "outputId": "0849ad4b-c56c-4463-e8ef-a59e9023d298"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on Google Colab, workdir: /gdrive/My Drive/projects/bambas\n",
            "Running on Google Colab, workdir: /gdrive/My Drive/projects/bambas\n",
            "Running on Google Colab, workdir: /gdrive/My Drive/projects/bambas\n",
            "Running on Google Colab, workdir: /gdrive/My Drive/projects/bambas\n",
            "Arguments: Namespace(classifier='MLP', dataset='semeval2024_test_unlabeled', train_features='/gdrive/My Drive/projects/bambas/feature_extraction/1708038514_jhu-clsp-bernice_train_features.json', test_features='/gdrive/My Drive/projects/bambas/feature_extraction/1708038514_jhu-clsp-bernice_test_features.json', dev_features='/gdrive/My Drive/projects/bambas/feature_extraction/1708038514_jhu-clsp-bernice_dev_features.json', max_iter=200, alpha=0.0001, seed=1, oversampling=None, sampling_strategy=None, concat_train_dev=False)\n",
            "Loading features info files\n",
            "Loading dataset files\n",
            "Dataset Lengths 7500 1000 1500\n",
            "Labels: [['Appeal to authority', 'Appeal to fear/prejudice', 'Bandwagon', 'Black-and-white Fallacy/Dictatorship', 'Causal Oversimplification', 'Doubt', 'Exaggeration/Minimisation', 'Flag-waving', 'Glittering generalities (Virtue)', 'Loaded Language', \"Misrepresentation of Someone's Position (Straw Man)\", 'Name calling/Labeling', 'Obfuscation, Intentional vagueness, Confusion', 'Presenting Irrelevant Data (Red Herring)', 'Reductio ad hitlerum', 'Repetition', 'Slogans', 'Smears', 'Thought-terminating cliché', 'Whataboutism']]\n",
            "No. of labels in train+dev datasets: 20\n",
            "Loading features array files\n",
            "Features Lengths 7500 1500 1000\n",
            "Iteration 1, loss = 5.31521631\n",
            "Validation score: 0.210667\n",
            "Iteration 2, loss = 4.17615958\n",
            "Validation score: 0.214667\n",
            "Iteration 3, loss = 3.93762691\n",
            "Validation score: 0.220000\n",
            "Iteration 4, loss = 3.82885719\n",
            "Validation score: 0.221333\n",
            "Iteration 5, loss = 3.76957126\n",
            "Validation score: 0.222667\n",
            "Iteration 6, loss = 3.68201779\n",
            "Validation score: 0.232000\n",
            "Iteration 7, loss = 3.61568111\n",
            "Validation score: 0.230667\n",
            "Iteration 8, loss = 3.56442903\n",
            "Validation score: 0.225333\n",
            "Iteration 9, loss = 3.51332343\n",
            "Validation score: 0.242667\n",
            "Iteration 10, loss = 3.52703191\n",
            "Validation score: 0.222667\n",
            "Iteration 11, loss = 3.44078804\n",
            "Validation score: 0.233333\n",
            "Iteration 12, loss = 3.41240641\n",
            "Validation score: 0.224000\n",
            "Iteration 13, loss = 3.36572312\n",
            "Validation score: 0.222667\n",
            "Iteration 14, loss = 3.36051294\n",
            "Validation score: 0.221333\n",
            "Iteration 15, loss = 3.29171297\n",
            "Validation score: 0.232000\n",
            "Iteration 16, loss = 3.26325800\n",
            "Validation score: 0.216000\n",
            "Iteration 17, loss = 3.23633928\n",
            "Validation score: 0.249333\n",
            "Iteration 18, loss = 3.18727942\n",
            "Validation score: 0.238667\n",
            "Iteration 19, loss = 3.17577623\n",
            "Validation score: 0.253333\n",
            "Iteration 20, loss = 3.14419816\n",
            "Validation score: 0.225333\n",
            "Iteration 21, loss = 3.09571882\n",
            "Validation score: 0.238667\n",
            "Iteration 22, loss = 3.05447117\n",
            "Validation score: 0.222667\n",
            "Iteration 23, loss = 3.01499642\n",
            "Validation score: 0.245333\n",
            "Iteration 24, loss = 2.98345142\n",
            "Validation score: 0.237333\n",
            "Iteration 25, loss = 2.96560952\n",
            "Validation score: 0.225333\n",
            "Iteration 26, loss = 2.91619723\n",
            "Validation score: 0.225333\n",
            "Iteration 27, loss = 2.91189372\n",
            "Validation score: 0.253333\n",
            "Iteration 28, loss = 2.85081333\n",
            "Validation score: 0.228000\n",
            "Iteration 29, loss = 2.81031222\n",
            "Validation score: 0.241333\n",
            "Iteration 30, loss = 2.74417886\n",
            "Validation score: 0.234667\n",
            "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "\n",
            "Validation set:\n",
            "\tPrecision: 0.7257187257187258\n",
            "\tRecall: 0.38876170655567116\n",
            "\tF1: 0.5063016668925329\n",
            "\n",
            "Saving validation set results to /gdrive/My Drive/projects/bambas/classification/results.csv\n",
            "Creating dir /gdrive/My Drive/projects/bambas/classification\n",
            "\n",
            "Predicting for test file\n",
            "Finished successfully. dev_unlabeled predictions saved at /gdrive/My Drive/projects/bambas/classification/1708039876_dev_unlabeled_predictions.json.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!PYTHONPATH=\"/gdrive/My Drive/projects/bambas\" python -m src.classification \\\n",
        "  --classifier \"HiMLP\" \\\n",
        "  --dataset semeval2024_test_unlabeled \\\n",
        "  --train_features \"/gdrive/My Drive/projects/bambas/feature_extraction/1708038514_jhu-clsp-bernice_train_features.json\" \\\n",
        "  --test_features \"/gdrive/My Drive/projects/bambas/feature_extraction/1708038514_jhu-clsp-bernice_test_features.json\" \\\n",
        "  --dev_features \"/gdrive/My Drive/projects/bambas/feature_extraction/1708038514_jhu-clsp-bernice_dev_features.json\" \\\n",
        "  --seed 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GCx75MG9HOKf",
        "outputId": "98f7511b-9097-4877-cf23-ed23f3b6e58e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on Google Colab, workdir: /gdrive/My Drive/projects/bambas\n",
            "Running on Google Colab, workdir: /gdrive/My Drive/projects/bambas\n",
            "Running on Google Colab, workdir: /gdrive/My Drive/projects/bambas\n",
            "Running on Google Colab, workdir: /gdrive/My Drive/projects/bambas\n",
            "Arguments: Namespace(classifier='HiMLP', dataset='semeval2024_test_unlabeled', train_features='/gdrive/My Drive/projects/bambas/feature_extraction/1708038514_jhu-clsp-bernice_train_features.json', test_features='/gdrive/My Drive/projects/bambas/feature_extraction/1708038514_jhu-clsp-bernice_test_features.json', dev_features='/gdrive/My Drive/projects/bambas/feature_extraction/1708038514_jhu-clsp-bernice_dev_features.json', max_iter=200, alpha=0.0001, seed=1, oversampling=None, sampling_strategy=None, concat_train_dev=False)\n",
            "Loading features info files\n",
            "Loading dataset files\n",
            "Dataset Lengths 7500 1000 1500\n",
            "Labels: [['Appeal to (Strong) Emotions', 'Appeal to authority', 'Obfuscation, Intentional vagueness, Confusion', 'Pathos', 'Ethos', 'Simplification', 'Reductio ad hitlerum', 'Reasoning', 'Black-and-white Fallacy/Dictatorship', 'Repetition', 'Exaggeration/Minimisation', 'Thought-terminating cliché', 'Smears', 'Loaded Language', 'Bandwagon', 'Logos', 'Whataboutism', 'Justification', 'Distraction', 'Name calling/Labeling', 'Causal Oversimplification', 'Glittering generalities (Virtue)', 'Presenting Irrelevant Data (Red Herring)', 'Flag-waving', 'Ad Hominem', 'Appeal to fear/prejudice', 'Doubt', 'Slogans', \"Misrepresentation of Someone's Position (Straw Man)\", 'Transfer']]\n",
            "No. of labels in DAG: 30\n",
            "Loading features array files\n",
            "Features Lengths 7500 1500 1000\n",
            "Iteration 1, loss = 1.31407431\n",
            "Validation score: 0.487856\n",
            "Iteration 2, loss = 1.05016921\n",
            "Validation score: 0.401804\n",
            "Iteration 3, loss = 1.05498563\n",
            "Validation score: 0.487856\n",
            "Iteration 4, loss = 1.04486606\n",
            "Validation score: 0.401804\n",
            "Iteration 5, loss = 1.05159210\n",
            "Validation score: 0.487856\n",
            "Iteration 6, loss = 1.04252955\n",
            "Validation score: 0.489244\n",
            "Iteration 7, loss = 1.04127613\n",
            "Validation score: 0.476058\n",
            "Iteration 8, loss = 1.04719292\n",
            "Validation score: 0.494101\n",
            "Iteration 9, loss = 1.03848035\n",
            "Validation score: 0.471201\n",
            "Iteration 10, loss = 1.03898434\n",
            "Validation score: 0.487856\n",
            "Iteration 11, loss = 1.03742136\n",
            "Validation score: 0.399722\n",
            "Iteration 12, loss = 1.03410782\n",
            "Validation score: 0.471201\n",
            "Iteration 13, loss = 1.03406557\n",
            "Validation score: 0.487162\n",
            "Iteration 14, loss = 1.03838704\n",
            "Validation score: 0.476058\n",
            "Iteration 15, loss = 1.03320236\n",
            "Validation score: 0.489938\n",
            "Iteration 16, loss = 1.03368760\n",
            "Validation score: 0.471895\n",
            "Iteration 17, loss = 1.03228737\n",
            "Validation score: 0.489244\n",
            "Iteration 18, loss = 1.03150985\n",
            "Validation score: 0.469813\n",
            "Iteration 19, loss = 1.03107368\n",
            "Validation score: 0.471201\n",
            "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 1.54927216\n",
            "Validation score: 0.549708\n",
            "Iteration 2, loss = 0.93637159\n",
            "Validation score: 0.500975\n",
            "Iteration 3, loss = 0.91451819\n",
            "Validation score: 0.411306\n",
            "Iteration 4, loss = 0.92468341\n",
            "Validation score: 0.411306\n",
            "Iteration 5, loss = 0.95487175\n",
            "Validation score: 0.549708\n",
            "Iteration 6, loss = 0.94049374\n",
            "Validation score: 0.549708\n",
            "Iteration 7, loss = 0.91440390\n",
            "Validation score: 0.549708\n",
            "Iteration 8, loss = 0.94434289\n",
            "Validation score: 0.397661\n",
            "Iteration 9, loss = 0.96114634\n",
            "Validation score: 0.549708\n",
            "Iteration 10, loss = 0.94659409\n",
            "Validation score: 0.549708\n",
            "Iteration 11, loss = 0.92238850\n",
            "Validation score: 0.549708\n",
            "Iteration 12, loss = 0.91679836\n",
            "Validation score: 0.411306\n",
            "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 1.20788747\n",
            "Validation score: 0.801932\n",
            "Iteration 2, loss = 0.67601840\n",
            "Validation score: 0.801932\n",
            "Iteration 3, loss = 0.54453183\n",
            "Validation score: 0.801932\n",
            "Iteration 4, loss = 0.50503181\n",
            "Validation score: 0.801932\n",
            "Iteration 5, loss = 0.50545350\n",
            "Validation score: 0.801932\n",
            "Iteration 6, loss = 0.50369562\n",
            "Validation score: 0.801932\n",
            "Iteration 7, loss = 0.50252371\n",
            "Validation score: 0.801932\n",
            "Iteration 8, loss = 0.50822364\n",
            "Validation score: 0.801932\n",
            "Iteration 9, loss = 0.50795945\n",
            "Validation score: 0.801932\n",
            "Iteration 10, loss = 0.50726705\n",
            "Validation score: 0.801932\n",
            "Iteration 11, loss = 0.50116922\n",
            "Validation score: 0.801932\n",
            "Iteration 12, loss = 0.51420399\n",
            "Validation score: 0.801932\n",
            "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 2.25216496\n",
            "Validation score: 0.367470\n",
            "Iteration 2, loss = 1.39521737\n",
            "Validation score: 0.379518\n",
            "Iteration 3, loss = 1.15244474\n",
            "Validation score: 0.379518\n",
            "Iteration 4, loss = 1.06672534\n",
            "Validation score: 0.500000\n",
            "Iteration 5, loss = 0.99149964\n",
            "Validation score: 0.512048\n",
            "Iteration 6, loss = 0.97043721\n",
            "Validation score: 0.500000\n",
            "Iteration 7, loss = 0.96166031\n",
            "Validation score: 0.512048\n",
            "Iteration 8, loss = 0.95155565\n",
            "Validation score: 0.512048\n",
            "Iteration 9, loss = 0.95751342\n",
            "Validation score: 0.500000\n",
            "Iteration 10, loss = 0.96318191\n",
            "Validation score: 0.379518\n",
            "Iteration 11, loss = 0.97194709\n",
            "Validation score: 0.512048\n",
            "Iteration 12, loss = 0.96976487\n",
            "Validation score: 0.512048\n",
            "Iteration 13, loss = 0.95292692\n",
            "Validation score: 0.379518\n",
            "Iteration 14, loss = 0.98466023\n",
            "Validation score: 0.512048\n",
            "Iteration 15, loss = 0.96299508\n",
            "Validation score: 0.500000\n",
            "Iteration 16, loss = 0.96444965\n",
            "Validation score: 0.500000\n",
            "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 1.76407670\n",
            "Validation score: 0.731707\n",
            "Iteration 2, loss = 2.68986385\n",
            "Validation score: 0.731707\n",
            "Iteration 3, loss = 2.14971511\n",
            "Validation score: 0.731707\n",
            "Iteration 4, loss = 1.51266788\n",
            "Validation score: 0.731707\n",
            "Iteration 5, loss = 1.21067576\n",
            "Validation score: 0.170732\n",
            "Iteration 6, loss = 1.26841500\n",
            "Validation score: 0.731707\n",
            "Iteration 7, loss = 1.08897027\n",
            "Validation score: 0.731707\n",
            "Iteration 8, loss = 1.16854530\n",
            "Validation score: 0.731707\n",
            "Iteration 9, loss = 1.17710595\n",
            "Validation score: 0.731707\n",
            "Iteration 10, loss = 0.91644804\n",
            "Validation score: 0.731707\n",
            "Iteration 11, loss = 0.92975180\n",
            "Validation score: 0.731707\n",
            "Iteration 12, loss = 1.01797055\n",
            "Validation score: 0.731707\n",
            "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 2.10210580\n",
            "Validation score: 0.404412\n",
            "Iteration 2, loss = 1.47121888\n",
            "Validation score: 0.441176\n",
            "Iteration 3, loss = 1.40282301\n",
            "Validation score: 0.275735\n",
            "Iteration 4, loss = 1.41947808\n",
            "Validation score: 0.275735\n",
            "Iteration 5, loss = 1.43716993\n",
            "Validation score: 0.441176\n",
            "Iteration 6, loss = 1.41017226\n",
            "Validation score: 0.441176\n",
            "Iteration 7, loss = 1.38550550\n",
            "Validation score: 0.441176\n",
            "Iteration 8, loss = 1.38143086\n",
            "Validation score: 0.275735\n",
            "Iteration 9, loss = 1.43379629\n",
            "Validation score: 0.275735\n",
            "Iteration 10, loss = 1.46177353\n",
            "Validation score: 0.441176\n",
            "Iteration 11, loss = 1.41422658\n",
            "Validation score: 0.441176\n",
            "Iteration 12, loss = 1.40607305\n",
            "Validation score: 0.393382\n",
            "Iteration 13, loss = 1.37136106\n",
            "Validation score: 0.441176\n",
            "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 1.18980530\n",
            "Validation score: 0.746269\n",
            "Iteration 2, loss = 0.77615615\n",
            "Validation score: 0.746269\n",
            "Iteration 3, loss = 0.80075034\n",
            "Validation score: 0.742952\n",
            "Iteration 4, loss = 0.77020916\n",
            "Validation score: 0.742952\n",
            "Iteration 5, loss = 0.75264361\n",
            "Validation score: 0.742952\n",
            "Iteration 6, loss = 0.75156692\n",
            "Validation score: 0.742952\n",
            "Iteration 7, loss = 0.75133225\n",
            "Validation score: 0.742952\n",
            "Iteration 8, loss = 0.74730861\n",
            "Validation score: 0.742952\n",
            "Iteration 9, loss = 0.75734334\n",
            "Validation score: 0.742952\n",
            "Iteration 10, loss = 0.74362763\n",
            "Validation score: 0.742952\n",
            "Iteration 11, loss = 0.76659655\n",
            "Validation score: 0.742952\n",
            "Iteration 12, loss = 0.75937295\n",
            "Validation score: 0.742952\n",
            "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 1.51975322\n",
            "Validation score: 0.605791\n",
            "Iteration 2, loss = 1.07692490\n",
            "Validation score: 0.605791\n",
            "Iteration 3, loss = 1.06258929\n",
            "Validation score: 0.605791\n",
            "Iteration 4, loss = 1.06923618\n",
            "Validation score: 0.605791\n",
            "Iteration 5, loss = 1.05677679\n",
            "Validation score: 0.358575\n",
            "Iteration 6, loss = 1.11540135\n",
            "Validation score: 0.605791\n",
            "Iteration 7, loss = 1.07443412\n",
            "Validation score: 0.605791\n",
            "Iteration 8, loss = 1.06318837\n",
            "Validation score: 0.605791\n",
            "Iteration 9, loss = 1.05408918\n",
            "Validation score: 0.605791\n",
            "Iteration 10, loss = 1.07197294\n",
            "Validation score: 0.605791\n",
            "Iteration 11, loss = 1.07850752\n",
            "Validation score: 0.605791\n",
            "Iteration 12, loss = 1.08288288\n",
            "Validation score: 0.605791\n",
            "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 1.64434196\n",
            "Validation score: 0.606154\n",
            "Iteration 2, loss = 1.07565663\n",
            "Validation score: 0.593846\n",
            "Iteration 3, loss = 1.06676301\n",
            "Validation score: 0.606154\n",
            "Iteration 4, loss = 1.04716799\n",
            "Validation score: 0.593846\n",
            "Iteration 5, loss = 1.04026492\n",
            "Validation score: 0.593846\n",
            "Iteration 6, loss = 1.04968532\n",
            "Validation score: 0.606154\n",
            "Iteration 7, loss = 1.07306371\n",
            "Validation score: 0.603077\n",
            "Iteration 8, loss = 1.06146538\n",
            "Validation score: 0.603077\n",
            "Iteration 9, loss = 1.05852671\n",
            "Validation score: 0.593846\n",
            "Iteration 10, loss = 1.04533405\n",
            "Validation score: 0.593846\n",
            "Iteration 11, loss = 1.03888033\n",
            "Validation score: 0.593846\n",
            "Iteration 12, loss = 1.03324000\n",
            "Validation score: 0.593846\n",
            "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "\n",
            "Validation set:\n",
            "\tPrecision: 0.625\n",
            "\tRecall: 0.002081165452653486\n",
            "\tF1: 0.0041485169052063895\n",
            "\n",
            "Saving validation set results to /gdrive/My Drive/projects/bambas/classification/results.csv\n",
            "\n",
            "Predicting for test file\n",
            "Finished successfully. dev_unlabeled predictions saved at /gdrive/My Drive/projects/bambas/classification/1708040356_dev_unlabeled_predictions.json.txt\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "interpreter": {
      "hash": "38cca0c38332a56087b24af0bc80247f4fced29cb4f7f437d91dc159adec9c4e"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}