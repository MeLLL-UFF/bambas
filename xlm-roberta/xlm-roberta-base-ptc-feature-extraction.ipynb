{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a58bb227-54cb-46ee-aa86-b4cc5a016e02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-09 14:56:44.363027: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-09 14:56:48.653318: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-11-09 14:56:48.657249: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-11-09 14:56:48.657261: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from emoji import demojize\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, multilabel_confusion_matrix\n",
    "\n",
    "DATASET_DIR = \"../dataset/ptc_adjust/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d01777c8-c362-4799-8149-7e147be169fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [text, label]\n",
       "Index: []"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(DATASET_DIR+\"ptc_preproc_train.csv\", sep=\";\").dropna(subset=[\"text\", \"label\"])[[\"text\", \"label\"]]\n",
    "train = train.drop_duplicates(subset=[\"text\"])\n",
    "test = pd.read_csv(DATASET_DIR+\"ptc_preproc_test.csv\", sep=\";\").dropna(subset=[\"text\", \"label\"])[[\"text\", \"label\"]]\n",
    "test = test.drop_duplicates(subset=[\"text\"])\n",
    "\n",
    "# This pd.DataFrame should be empty\n",
    "pd.concat([test[test.text.isnull()],train[train.text.isnull()]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09ab54d7-b615-4114-be91-5f16ed823f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model_name = \"xlm-roberta-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=False, normalization=True)\n",
    "model = AutoModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6c22941-0a39-414a-9e17-92ae235670a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0               [0, 42284, 3726, 47691, 111, 21629, 5, 2]\n",
       "1       [0, 1401, 158, 4545, 19, 756, 8382, 124901, 22...\n",
       "2                    [0, 262, 88981, 3291, 8408, 1135, 2]\n",
       "3       [0, 70, 64857, 450, 26038, 70, 8999, 70, 14069...\n",
       "4       [0, 581, 17274, 5608, 8306, 24209, 10, 36541, ...\n",
       "                              ...                        \n",
       "1375    [0, 10, 6782, 23972, 62, 25965, 674, 91375, 53...\n",
       "1376                   [0, 5879, 9, 2943, 214, 131161, 2]\n",
       "1377                           [0, 17202, 7941, 16070, 2]\n",
       "1378                [0, 51, 14473, 5874, 38526, 83024, 2]\n",
       "1379                                 [0, 58867, 46667, 2]\n",
       "Name: text, Length: 5674, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.concat((train[\"text\"], test[\"text\"]))\n",
    "tokens = data.apply((lambda x: tokenizer.encode(\n",
    "    x,\n",
    "    # add_special_tokens=True,\n",
    "    truncation=True,\n",
    "    # padding=True,\n",
    "    max_length=128\n",
    ")))\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c7b0774-a9cd-4351-a547-184a0b311b07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5674, 128)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded = np.array([token+[0]*(128-len(token)) for token in tokens.values])\n",
    "np.array(padded).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9041fba-385f-4d0f-b964-8d85ecf9ee7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5674, 128)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_mask = np.where(padded != 0, 1, 0)\n",
    "attention_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac4fb6bd-8bc7-41e2-b370-644b5113846c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features shape: (5674, 768)\n"
     ]
    }
   ],
   "source": [
    "input_ids = torch.tensor(padded)\n",
    "attention_mask = torch.tensor(attention_mask)\n",
    "with torch.no_grad():\n",
    "    last_hidden_states = model(input_ids, attention_mask=attention_mask)\n",
    "\n",
    "# extract [CLS] token hidden representation from output layer\n",
    "features = last_hidden_states[0][:,0,:].numpy()\n",
    "print(f'features shape: {features.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train features: 4464\n",
      "test features: 1210\n"
     ]
    }
   ],
   "source": [
    "train_features, test_features = features[:-len(test)], features[len(train):]\n",
    "print(f'train features: {len(train_features)}')\n",
    "print(f'test features: {len(test_features)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(50, ['Loaded_Language', 'Slogans']),\n",
       " (110,\n",
       "  ['Appeal_to_Authority',\n",
       "   'Appeal_to_fear-prejudice',\n",
       "   'Exaggeration_Minimisation',\n",
       "   'Repetition']),\n",
       " (111, ['Appeal_to_Authority', 'Exaggeration_Minimisation']),\n",
       " (114, ['Exaggeration_Minimisation', 'Repetition']),\n",
       " (115, ['Appeal_to_fear-prejudice', 'Repetition']),\n",
       " (116, ['Appeal_to_Authority', 'Appeal_to_fear-prejudice']),\n",
       " (122, ['Appeal_to_Authority', 'Repetition']),\n",
       " (125, ['Appeal_to_Authority', 'Appeal_to_fear-prejudice']),\n",
       " (139, ['Appeal_to_Authority', 'Exaggeration_Minimisation']),\n",
       " (181, ['Appeal_to_Authority', 'Exaggeration_Minimisation']),\n",
       " (191, ['Causal_Oversimplification', 'Exaggeration_Minimisation']),\n",
       " (210, ['Appeal_to_Authority', 'Exaggeration_Minimisation']),\n",
       " (252, ['Appeal_to_Authority', 'Repetition']),\n",
       " (253, ['Appeal_to_Authority', 'Repetition']),\n",
       " (255, ['Appeal_to_Authority', 'Exaggeration_Minimisation']),\n",
       " (267, ['Appeal_to_fear-prejudice', 'Black-and-White_Fallacy']),\n",
       " (282, ['Appeal_to_fear-prejudice', 'Loaded_Language']),\n",
       " (287, ['Appeal_to_Authority', 'Appeal_to_fear-prejudice', 'Repetition']),\n",
       " (288, ['Appeal_to_Authority', 'Repetition']),\n",
       " (296, ['Appeal_to_fear-prejudice', 'Repetition']),\n",
       " (352, ['Loaded_Language', 'Slogans']),\n",
       " (364, ['Appeal_to_fear-prejudice', 'Flag-Waving', 'Loaded_Language']),\n",
       " (373, ['Appeal_to_fear-prejudice', 'Flag-Waving']),\n",
       " (438, ['Exaggeration_Minimisation', 'Loaded_Language']),\n",
       " (446, ['Appeal_to_fear-prejudice', 'Flag-Waving']),\n",
       " (467, ['Exaggeration_Minimisation', 'Loaded_Language']),\n",
       " (468, ['Doubt', 'Exaggeration_Minimisation']),\n",
       " (505, ['Appeal_to_fear-prejudice', 'Loaded_Language']),\n",
       " (510, ['Name_Calling_Labeling', 'Repetition']),\n",
       " (538, ['Repetition', 'Slogans']),\n",
       " (554, ['Flag-Waving', 'Slogans']),\n",
       " (595, ['Flag-Waving', 'Repetition']),\n",
       " (614, ['Doubt', 'Exaggeration_Minimisation']),\n",
       " (691, ['Appeal_to_fear-prejudice', 'Loaded_Language']),\n",
       " (932, ['Loaded_Language', 'Repetition']),\n",
       " (964, ['Exaggeration_Minimisation', 'Loaded_Language']),\n",
       " (990, ['Appeal_to_fear-prejudice', 'Name_Calling_Labeling']),\n",
       " (1013, ['Appeal_to_fear-prejudice', 'Loaded_Language']),\n",
       " (1018, ['Appeal_to_fear-prejudice', 'Bandwagon']),\n",
       " (1032, ['Appeal_to_fear-prejudice', 'Loaded_Language']),\n",
       " (1105, ['Exaggeration_Minimisation', 'Repetition']),\n",
       " (1108, ['Flag-Waving', 'Thought-terminating_Cliches']),\n",
       " (1109, ['Flag-Waving', 'Thought-terminating_Cliches']),\n",
       " (1110, ['Flag-Waving', 'Thought-terminating_Cliches']),\n",
       " (1116, ['Appeal_to_fear-prejudice', 'Black-and-White_Fallacy'])]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels, test_labels = train[\"label\"].to_numpy(), test[\"label\"].to_numpy()\n",
    "\n",
    "train_labels = [label.split(\",\") for label in train_labels]\n",
    "test_labels = [label.split(\",\") for label in test_labels]\n",
    "\n",
    "[(idx,labels) for idx,labels in enumerate(test_labels) if len(labels)>1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "41384008-6c93-4963-a0fd-88c54a2d59c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_labels, test_labels = train[\"label\"].to_numpy(), test[\"label\"].to_numpy()\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "train_labels_binarized = mlb.fit_transform(train_labels)\n",
    "test_labels_binarized = mlb.fit_transform(test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 6.42800591\n",
      "Validation score: 0.000000\n",
      "Iteration 2, loss = 3.18817855\n",
      "Validation score: 0.069351\n",
      "Iteration 3, loss = 3.01619315\n",
      "Validation score: 0.098434\n",
      "Iteration 4, loss = 2.93351221\n",
      "Validation score: 0.167785\n",
      "Iteration 5, loss = 2.86609473\n",
      "Validation score: 0.131991\n",
      "Iteration 6, loss = 2.80074188\n",
      "Validation score: 0.172260\n",
      "Iteration 7, loss = 2.75014343\n",
      "Validation score: 0.190157\n",
      "Iteration 8, loss = 2.70152061\n",
      "Validation score: 0.154362\n",
      "Iteration 9, loss = 2.66371236\n",
      "Validation score: 0.158837\n",
      "Iteration 10, loss = 2.62773229\n",
      "Validation score: 0.185682\n",
      "Iteration 11, loss = 2.59538986\n",
      "Validation score: 0.230425\n",
      "Iteration 12, loss = 2.57292016\n",
      "Validation score: 0.208054\n",
      "Iteration 13, loss = 2.55264689\n",
      "Validation score: 0.219239\n",
      "Iteration 14, loss = 2.52619128\n",
      "Validation score: 0.201342\n",
      "Iteration 15, loss = 2.50599701\n",
      "Validation score: 0.210291\n",
      "Iteration 16, loss = 2.47995805\n",
      "Validation score: 0.230425\n",
      "Iteration 17, loss = 2.46700481\n",
      "Validation score: 0.223714\n",
      "Iteration 18, loss = 2.44246351\n",
      "Validation score: 0.203579\n",
      "Iteration 19, loss = 2.42717119\n",
      "Validation score: 0.203579\n",
      "Iteration 20, loss = 2.40711676\n",
      "Validation score: 0.183445\n",
      "Iteration 21, loss = 2.39819993\n",
      "Validation score: 0.214765\n",
      "Iteration 22, loss = 2.38190227\n",
      "Validation score: 0.250559\n",
      "Iteration 23, loss = 2.36897249\n",
      "Validation score: 0.203579\n",
      "Iteration 24, loss = 2.35998475\n",
      "Validation score: 0.221477\n",
      "Iteration 25, loss = 2.34308681\n",
      "Validation score: 0.237136\n",
      "Iteration 26, loss = 2.32578735\n",
      "Validation score: 0.248322\n",
      "Iteration 27, loss = 2.31197221\n",
      "Validation score: 0.255034\n",
      "Iteration 28, loss = 2.31196288\n",
      "Validation score: 0.270694\n",
      "Iteration 29, loss = 2.29151153\n",
      "Validation score: 0.214765\n",
      "Iteration 30, loss = 2.28870214\n",
      "Validation score: 0.284116\n",
      "Iteration 31, loss = 2.27489313\n",
      "Validation score: 0.268456\n",
      "Iteration 32, loss = 2.26818842\n",
      "Validation score: 0.268456\n",
      "Iteration 33, loss = 2.25397463\n",
      "Validation score: 0.246085\n",
      "Iteration 34, loss = 2.24220354\n",
      "Validation score: 0.214765\n",
      "Iteration 35, loss = 2.24673578\n",
      "Validation score: 0.241611\n",
      "Iteration 36, loss = 2.22718947\n",
      "Validation score: 0.266219\n",
      "Iteration 37, loss = 2.21698941\n",
      "Validation score: 0.255034\n",
      "Iteration 38, loss = 2.20997588\n",
      "Validation score: 0.286353\n",
      "Iteration 39, loss = 2.20278752\n",
      "Validation score: 0.246085\n",
      "Iteration 40, loss = 2.19407488\n",
      "Validation score: 0.266219\n",
      "Iteration 41, loss = 2.18134857\n",
      "Validation score: 0.263982\n",
      "Iteration 42, loss = 2.17709454\n",
      "Validation score: 0.281879\n",
      "Iteration 43, loss = 2.17133627\n",
      "Validation score: 0.302013\n",
      "Iteration 44, loss = 2.16734521\n",
      "Validation score: 0.275168\n",
      "Iteration 45, loss = 2.15557207\n",
      "Validation score: 0.266219\n",
      "Iteration 46, loss = 2.16001455\n",
      "Validation score: 0.324385\n",
      "Iteration 47, loss = 2.14480660\n",
      "Validation score: 0.268456\n",
      "Iteration 48, loss = 2.13142315\n",
      "Validation score: 0.277405\n",
      "Iteration 49, loss = 2.13019096\n",
      "Validation score: 0.272931\n",
      "Iteration 50, loss = 2.11938710\n",
      "Validation score: 0.304251\n",
      "Iteration 51, loss = 2.11141595\n",
      "Validation score: 0.288591\n",
      "Iteration 52, loss = 2.10665591\n",
      "Validation score: 0.257271\n",
      "Iteration 53, loss = 2.10404596\n",
      "Validation score: 0.272931\n",
      "Iteration 54, loss = 2.09118476\n",
      "Validation score: 0.315436\n",
      "Iteration 55, loss = 2.09121041\n",
      "Validation score: 0.286353\n",
      "Iteration 56, loss = 2.07789518\n",
      "Validation score: 0.299776\n",
      "Iteration 57, loss = 2.07074569\n",
      "Validation score: 0.297539\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ff = MLPClassifier(\n",
    "    random_state=1,\n",
    "    max_iter=400,\n",
    "    alpha=0.001,\n",
    "    shuffle=True,\n",
    "    early_stopping=True,\n",
    "    verbose=True\n",
    ").fit(train_features, train_labels_binarized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "50ec2fcf-220f-418a-bb57-76cf8be1253a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micro-f1: 0.383618455158113\n",
      "accuracy: 0.2834710743801653\n",
      "micro-precision: 0.5522388059701493\n",
      "micro-recall: 0.29388403494837173\n"
     ]
    }
   ],
   "source": [
    "test_predicted_labels_binarized = ff.predict(test_features)\n",
    "micro_f1 = f1_score(test_labels_binarized, test_predicted_labels_binarized, average=\"micro\")\n",
    "acc = accuracy_score(test_labels_binarized, test_predicted_labels_binarized)\n",
    "prec = precision_score(test_labels_binarized, test_predicted_labels_binarized, average=\"micro\")\n",
    "rec = recall_score(test_labels_binarized, test_predicted_labels_binarized, average=\"micro\")\n",
    "print(f'micro-f1: {micro_f1}')\n",
    "print(f'accuracy: {acc}')\n",
    "print(f'micro-precision: {prec}')\n",
    "print(f'micro-recall: {rec}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "39f72ed2-28dc-4370-8e77-161652131873",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1161,    0],\n",
       "        [  49,    0]],\n",
       "\n",
       "       [[1082,    0],\n",
       "        [ 127,    1]],\n",
       "\n",
       "       [[1206,    0],\n",
       "        [   4,    0]],\n",
       "\n",
       "       [[1185,    0],\n",
       "        [  25,    0]],\n",
       "\n",
       "       [[1179,    0],\n",
       "        [  31,    0]],\n",
       "\n",
       "       [[1134,    5],\n",
       "        [  67,    4]],\n",
       "\n",
       "       [[1111,   14],\n",
       "        [  82,    3]],\n",
       "\n",
       "       [[1131,    1],\n",
       "        [  67,   11]],\n",
       "\n",
       "       [[ 565,  250],\n",
       "        [  94,  301]],\n",
       "\n",
       "       [[1006,   25],\n",
       "        [ 130,   49]],\n",
       "\n",
       "       [[1204,    0],\n",
       "        [   6,    0]],\n",
       "\n",
       "       [[1198,    0],\n",
       "        [  12,    0]],\n",
       "\n",
       "       [[1198,    0],\n",
       "        [  12,    0]],\n",
       "\n",
       "       [[1096,    1],\n",
       "        [ 112,    1]],\n",
       "\n",
       "       [[1175,    1],\n",
       "        [  34,    0]],\n",
       "\n",
       "       [[1208,    0],\n",
       "        [   2,    0]],\n",
       "\n",
       "       [[1191,    3],\n",
       "        [  16,    0]],\n",
       "\n",
       "       [[1191,    0],\n",
       "        [  19,    0]]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cf_mtx = multilabel_confusion_matrix(test_labels_binarized, test_predicted_labels_binarized)\n",
    "cf_mtx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Appeal_to_Authority', 'Appeal_to_fear-prejudice', 'Bandwagon',\n",
       "       'Black-and-White_Fallacy', 'Causal_Oversimplification', 'Doubt',\n",
       "       'Exaggeration_Minimisation', 'Flag-Waving', 'Loaded_Language',\n",
       "       'Name_Calling_Labeling',\n",
       "       'Obfuscation_Intentional_Vagueness_Confusion', 'Red_Herring',\n",
       "       'Reductio_ad_hitlerum', 'Repetition', 'Slogans', 'Straw_Men',\n",
       "       'Thought-terminating_Cliches', 'Whataboutism'], dtype='<U43')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels_array = []\n",
    "for label_list in test_labels:\n",
    "    for label in label_list:\n",
    "        test_labels_array.append(label)\n",
    "\n",
    "(np.unique(np.array(test_labels_array)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
