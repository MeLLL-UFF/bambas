{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a58bb227-54cb-46ee-aa86-b4cc5a016e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from emoji import demojize\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, multilabel_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d01777c8-c362-4799-8149-7e147be169fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [text, label]\n",
       "Index: []"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"./dataset/ptc_preproc_train.csv\", sep=\";\").dropna(subset=[\"text\", \"label\"])[[\"text\", \"label\"]]\n",
    "train = train.drop_duplicates(subset=[\"text\"])\n",
    "test = pd.read_csv(\"./dataset/ptc_preproc_test.csv\", sep=\";\").dropna(subset=[\"text\", \"label\"])[[\"text\", \"label\"]]\n",
    "test = test.drop_duplicates(subset=[\"text\"])\n",
    "\n",
    "# This pd.DataFrame should be empty\n",
    "pd.concat([test[test.text.isnull()],train[train.text.isnull()]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4464, 1210, 5674)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train), len(test), len(train) + len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text     1210\n",
       "label    1210\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([train, test])[4464:].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "09ab54d7-b615-4114-be91-5f16ed823f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model_name = \"xlm-roberta-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=False, normalization=True)\n",
    "model = AutoModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a6c22941-0a39-414a-9e17-92ae235670a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0               [0, 42284, 3726, 47691, 111, 21629, 5, 2]\n",
       "1       [0, 1401, 158, 4545, 19, 756, 8382, 124901, 22...\n",
       "2                    [0, 262, 88981, 3291, 8408, 1135, 2]\n",
       "3       [0, 70, 64857, 450, 26038, 70, 8999, 70, 14069...\n",
       "4       [0, 581, 17274, 5608, 8306, 24209, 10, 36541, ...\n",
       "                              ...                        \n",
       "1375    [0, 10, 6782, 23972, 62, 25965, 674, 91375, 53...\n",
       "1376                   [0, 5879, 9, 2943, 214, 131161, 2]\n",
       "1377                           [0, 17202, 7941, 16070, 2]\n",
       "1378                [0, 51, 14473, 5874, 38526, 83024, 2]\n",
       "1379                                 [0, 58867, 46667, 2]\n",
       "Name: text, Length: 5674, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.concat((train[\"text\"], test[\"text\"]))\n",
    "tokens = data.apply((lambda x: tokenizer.encode(\n",
    "    x,\n",
    "    # add_special_tokens=True,\n",
    "    truncation=True,\n",
    "    # padding=True,\n",
    "    max_length=128\n",
    ")))\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4c7b0774-a9cd-4351-a547-184a0b311b07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5674, 128)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded = np.array([token+[0]*(128-len(token)) for token in tokens.values])\n",
    "np.array(padded).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e9041fba-385f-4d0f-b964-8d85ecf9ee7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5674, 128)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_mask = np.where(padded != 0, 1, 0)\n",
    "attention_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ac4fb6bd-8bc7-41e2-b370-644b5113846c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features shape: (5674, 768)\n"
     ]
    }
   ],
   "source": [
    "input_ids = torch.tensor(padded)\n",
    "attention_mask = torch.tensor(attention_mask)\n",
    "with torch.no_grad():\n",
    "    last_hidden_states = model(input_ids, attention_mask=attention_mask)\n",
    "\n",
    "# extract [CLS] token hidden representation from output layer\n",
    "features = last_hidden_states[0][:,0,:].numpy()\n",
    "print(f'features shape: {features.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train features: 4464\n",
      "test features: 1210\n"
     ]
    }
   ],
   "source": [
    "train_features, test_features = features[:-len(test)], features[len(train):]\n",
    "print(f'train features: {len(train_features)}')\n",
    "print(f'test features: {len(test_features)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "41384008-6c93-4963-a0fd-88c54a2d59c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 23.42109472\n",
      "Validation score: 0.004474\n",
      "Iteration 2, loss = 16.06559124\n",
      "Validation score: 0.013423\n",
      "Iteration 3, loss = 15.32512769\n",
      "Validation score: 0.038031\n",
      "Iteration 4, loss = 14.99810445\n",
      "Validation score: 0.174497\n",
      "Iteration 5, loss = 14.71179513\n",
      "Validation score: 0.029083\n",
      "Iteration 6, loss = 14.45220230\n",
      "Validation score: 0.129754\n",
      "Iteration 7, loss = 14.23660908\n",
      "Validation score: 0.192394\n",
      "Iteration 8, loss = 14.06472775\n",
      "Validation score: 0.149888\n",
      "Iteration 9, loss = 13.89430295\n",
      "Validation score: 0.129754\n",
      "Iteration 10, loss = 13.77924536\n",
      "Validation score: 0.143177\n",
      "Iteration 11, loss = 13.64704660\n",
      "Validation score: 0.174497\n",
      "Iteration 12, loss = 13.53689579\n",
      "Validation score: 0.161074\n",
      "Iteration 13, loss = 13.43610544\n",
      "Validation score: 0.158837\n",
      "Iteration 14, loss = 13.33087999\n",
      "Validation score: 0.250559\n",
      "Iteration 15, loss = 13.27238318\n",
      "Validation score: 0.210291\n",
      "Iteration 16, loss = 13.18447943\n",
      "Validation score: 0.205817\n",
      "Iteration 17, loss = 13.10518257\n",
      "Validation score: 0.154362\n",
      "Iteration 18, loss = 13.06467254\n",
      "Validation score: 0.237136\n",
      "Iteration 19, loss = 12.99383451\n",
      "Validation score: 0.248322\n",
      "Iteration 20, loss = 12.92654699\n",
      "Validation score: 0.239374\n",
      "Iteration 21, loss = 12.87510566\n",
      "Validation score: 0.246085\n",
      "Iteration 22, loss = 12.81772031\n",
      "Validation score: 0.237136\n",
      "Iteration 23, loss = 12.80357242\n",
      "Validation score: 0.290828\n",
      "Iteration 24, loss = 12.74877365\n",
      "Validation score: 0.234899\n",
      "Iteration 25, loss = 12.66169287\n",
      "Validation score: 0.223714\n",
      "Iteration 26, loss = 12.63617340\n",
      "Validation score: 0.194631\n",
      "Iteration 27, loss = 12.59906933\n",
      "Validation score: 0.199105\n",
      "Iteration 28, loss = 12.54557587\n",
      "Validation score: 0.194631\n",
      "Iteration 29, loss = 12.51339724\n",
      "Validation score: 0.210291\n",
      "Iteration 30, loss = 12.49530740\n",
      "Validation score: 0.250559\n",
      "Iteration 31, loss = 12.43915071\n",
      "Validation score: 0.243848\n",
      "Iteration 32, loss = 12.37162079\n",
      "Validation score: 0.225951\n",
      "Iteration 33, loss = 12.32639118\n",
      "Validation score: 0.239374\n",
      "Iteration 34, loss = 12.29830978\n",
      "Validation score: 0.237136\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    }
   ],
   "source": [
    "train_labels, test_labels = train[\"label\"].to_numpy(), test[\"label\"].to_numpy()\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "train_labels_binarized = mlb.fit_transform(train_labels)\n",
    "test_labels_binarized = mlb.fit_transform(test_labels)\n",
    "\n",
    "ff = MLPClassifier(\n",
    "    random_state=1,\n",
    "    max_iter=400,\n",
    "    alpha=0.001,\n",
    "    shuffle=True,\n",
    "    early_stopping=True,\n",
    "    verbose=True\n",
    ").fit(train_features, train_labels_binarized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "50ec2fcf-220f-418a-bb57-76cf8be1253a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micro-f1: 0.6718671783747706\n",
      "accuracy: 0.24049586776859505\n",
      "micro-precision: 0.753885040254634\n",
      "micro-recall: 0.6059443190368698\n"
     ]
    }
   ],
   "source": [
    "test_predicted_labels_binarized = ff.predict(test_features)\n",
    "micro_f1 = f1_score(test_labels_binarized, test_predicted_labels_binarized, average=\"micro\")\n",
    "acc = accuracy_score(test_labels_binarized, test_predicted_labels_binarized)\n",
    "prec = precision_score(test_labels_binarized, test_predicted_labels_binarized, average=\"micro\")\n",
    "rec = recall_score(test_labels_binarized, test_predicted_labels_binarized, average=\"micro\")\n",
    "print(f'micro-f1: {micro_f1}')\n",
    "print(f'accuracy: {acc}')\n",
    "print(f'micro-precision: {prec}')\n",
    "print(f'micro-recall: {rec}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "39f72ed2-28dc-4370-8e77-161652131873",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1165,    0],\n",
       "        [  45,    0]],\n",
       "\n",
       "       [[ 971,    0],\n",
       "        [ 239,    0]],\n",
       "\n",
       "       [[1037,    0],\n",
       "        [ 173,    0]],\n",
       "\n",
       "       [[1181,    0],\n",
       "        [  29,    0]],\n",
       "\n",
       "       [[ 960,   18],\n",
       "        [ 198,   34]],\n",
       "\n",
       "       [[1139,    0],\n",
       "        [  71,    0]],\n",
       "\n",
       "       [[1125,    0],\n",
       "        [  85,    0]],\n",
       "\n",
       "       [[1107,    0],\n",
       "        [ 103,    0]],\n",
       "\n",
       "       [[1198,    0],\n",
       "        [  12,    0]],\n",
       "\n",
       "       [[1204,    0],\n",
       "        [   6,    0]],\n",
       "\n",
       "       [[ 382,  254],\n",
       "        [  55,  519]],\n",
       "\n",
       "       [[1123,    0],\n",
       "        [  87,    0]],\n",
       "\n",
       "       [[1002,   29],\n",
       "        [ 134,   45]],\n",
       "\n",
       "       [[1173,    0],\n",
       "        [  37,    0]],\n",
       "\n",
       "       [[1073,    0],\n",
       "        [ 137,    0]],\n",
       "\n",
       "       [[1174,    0],\n",
       "        [  36,    0]],\n",
       "\n",
       "       [[1194,    0],\n",
       "        [  16,    0]],\n",
       "\n",
       "       [[1204,    0],\n",
       "        [   6,    0]],\n",
       "\n",
       "       [[1088,    0],\n",
       "        [ 122,    0]],\n",
       "\n",
       "       [[  11,  282],\n",
       "        [   5,  912]],\n",
       "\n",
       "       [[   0,  180],\n",
       "        [   0, 1030]],\n",
       "\n",
       "       [[ 923,   12],\n",
       "        [ 259,   16]],\n",
       "\n",
       "       [[ 989,    5],\n",
       "        [ 212,    4]],\n",
       "\n",
       "       [[ 332,  311],\n",
       "        [ 145,  422]],\n",
       "\n",
       "       [[   4,  188],\n",
       "        [   2, 1016]],\n",
       "\n",
       "       [[1045,    0],\n",
       "        [ 164,    1]],\n",
       "\n",
       "       [[ 164,  247],\n",
       "        [  80,  719]],\n",
       "\n",
       "       [[1089,    0],\n",
       "        [ 121,    0]],\n",
       "\n",
       "       [[ 380,  109],\n",
       "        [ 361,  360]],\n",
       "\n",
       "       [[1082,    0],\n",
       "        [ 128,    0]],\n",
       "\n",
       "       [[1185,    0],\n",
       "        [  25,    0]],\n",
       "\n",
       "       [[ 608,   58],\n",
       "        [ 431,  113]],\n",
       "\n",
       "       [[ 811,   58],\n",
       "        [ 275,   66]],\n",
       "\n",
       "       [[  57,  191],\n",
       "        [  36,  926]],\n",
       "\n",
       "       [[  51,  233],\n",
       "        [  24,  902]],\n",
       "\n",
       "       [[ 901,    0],\n",
       "        [ 309,    0]],\n",
       "\n",
       "       [[ 847,   39],\n",
       "        [ 281,   43]],\n",
       "\n",
       "       [[1014,    6],\n",
       "        [ 188,    2]],\n",
       "\n",
       "       [[ 579,   99],\n",
       "        [ 251,  281]],\n",
       "\n",
       "       [[ 183,  310],\n",
       "        [  75,  642]],\n",
       "\n",
       "       [[1101,    0],\n",
       "        [ 109,    0]],\n",
       "\n",
       "       [[1204,    0],\n",
       "        [   6,    0]],\n",
       "\n",
       "       [[1125,    0],\n",
       "        [  85,    0]],\n",
       "\n",
       "       [[1136,    0],\n",
       "        [  74,    0]]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cf_mtx = multilabel_confusion_matrix(test_labels_binarized, test_predicted_labels_binarized)\n",
    "cf_mtx"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
